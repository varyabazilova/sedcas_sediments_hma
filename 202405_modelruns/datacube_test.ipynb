{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab049826-da3f-4c5b-97a4-2f5455a6edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be538229-75fb-4cba-8732-9e460bcf6fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['Longitude_new', 'Latitude_new', 'index', 'annual_mean_Qstl_mm', 'annual_25percent_Qstl_mm', 'annual_50percent_Qstl_mm', 'annual_75percent_Qstl_mm']\n",
    "\n",
    "langtang = pd.read_csv('/Users/varyabazilova/Desktop/paper2/202405_modelruns/1langtangTL/default_land_cover/default_land_coverlangtang_tl_percentiles_with_coords.csv')\n",
    "langtang = langtang.rename(columns = {'index': 'cellnr2'})\n",
    "langtang = langtang[['cellnr2', 'Latitude_new', 'Longitude_new']]\n",
    "# langtang = langtang.set_index('cellnr2')\n",
    "\n",
    "elevation = pd.read_csv('/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_and_elevation_with_labels_langtang.csv')[['cellnr2','band_data']]\n",
    "# elevation = elevation.set_index('cellnr2')\n",
    "\n",
    "langtang = langtang.merge(elevation, on = 'cellnr2')\n",
    "langtang = langtang.set_index('cellnr2')\n",
    "\n",
    "location_df = langtang\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c993a75-9233-45e8-90f3-986c595dd560",
   "metadata": {},
   "source": [
    "# make monthly data and save to each folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bad70d2e-ede3-4ee3-b77f-650022c65cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/varyabazilova/Desktop/paper2/202405_modelruns/xrds_test/'\n",
    "\n",
    "# df = pd.read_csv(path + 'cellnr12a/Sediment.out')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0b35dab-43b6-4d0c-9707-a7886784bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = functions.calculate_monthly_sediment_yield_all(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9ba452b-972f-47cb-95b4-f441c935bb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cellnr12b\n",
      "cellnr12d\n",
      "cellnr12c\n",
      "cellnr13a\n",
      "cellnr12a\n",
      "cellnr13d\n",
      "cellnr13c\n",
      "cellnr13b\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "for folder_name in os.listdir(path):\n",
    "    # skip dsstore thing\n",
    "    if folder_name == '.DS_Store':\n",
    "        continue\n",
    "    if folder_name == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    # skip all csvs\n",
    "    if folder_name.endswith('.csv'):\n",
    "        continue\n",
    "    print(folder_name)\n",
    "    # Extract location_id from the last 3 characters of the folder name\n",
    "    location_id = folder_name[-3:]\n",
    "\n",
    "    if location_id in location_df.index:\n",
    "        location_info = location_df.loc[location_id]\n",
    "        \n",
    "        elevation = location_info['band_data']\n",
    "        lat = location_info['Latitude_new']\n",
    "        lon = location_info['Longitude_new']\n",
    "\n",
    "        sediment_file = os.path.join(path, folder_name, 'Sediment.out')\n",
    "        sediment_data = functions.calculate_monthly_sediment_yield_all(pd.read_csv(sediment_file)[['D', 'Q100']])\n",
    "        sediment_data['D'] = pd.to_datetime(sediment_data.D)\n",
    "\n",
    "          # Create xarray dataset\n",
    "        ds = xr.Dataset(\n",
    "            data_vars={col: (('time',), sediment_data[col]) for col in sediment_data.columns},\n",
    "            coords={'time': sediment_data['D'].values}\n",
    "        )\n",
    "\n",
    "        # Convert latitude and longitude coordinates to dimensions\n",
    "        ds_with_dims = ds.expand_dims({'latitude': [lat], 'longitude': [lon]}, axis=(1, 2))\n",
    "        \n",
    "        # datasets.append(ds_with_dims)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f095cf6b-0e52-4ff2-b4e9-3fd86d461b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Assuming datasets is a list containing your datasets\n",
    "\n",
    "# # Extract latitude and longitude values from each dataset\n",
    "# latitude_values = [ds['latitude'].data[0] for ds in datasets]\n",
    "# longitude_values = [ds['longitude'].data[0] for ds in datasets]\n",
    "\n",
    "# # Create DataArrays for latitude and longitude dimensions\n",
    "# latitude_dim = xr.DataArray(latitude_values, dims='location')\n",
    "# longitude_dim = xr.DataArray(longitude_values, dims='location')\n",
    "\n",
    "# Combine datasets along the time dimension\n",
    "combined_ds = xr.concat(datasets, dim='time')\n",
    "\n",
    "# Create a new dimension for latitude\n",
    "# latitude_dim_combined = xr.DataArray(range(len(datasets))#, dims='location')\n",
    "\n",
    "# Assign latitude and longitude as dimensions\n",
    "# combined_ds = combined_ds.assign_coords(latitude=(('location',), latitude_dim_combined),\n",
    "#                                         longitude=(('location',), longitude_dim))\n",
    "\n",
    "combined_ds = combined_ds.assign_coords(latitude=latitude_dim, longitude=longitude_dim)\n",
    "\n",
    "# Print the combined dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d7dc162-176c-4de8-9ef3-c7ac0db5fa4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<xarray.Dataset>\n",
       " Dimensions:    (time: 853, latitude: 1, longitude: 1)\n",
       " Coordinates:\n",
       "   * latitude   (latitude) float64 28.07\n",
       "   * longitude  (longitude) float64 85.53\n",
       "   * time       (time) datetime64[ns] 1951-09-30 1951-10-31 ... 2022-09-30\n",
       " Data variables:\n",
       "     D          (time, latitude, longitude) datetime64[ns] 1951-09-30 ... 2022...\n",
       "     Q100       (time, latitude, longitude) float64 0.0 2.917e+04 ... 5.473e+04\n",
       "     year       (time, latitude, longitude) int64 1951 1951 1951 ... 2022 2022\n",
       "     month      (time, latitude, longitude) int64 9 10 11 12 1 2 ... 4 5 6 7 8 9,\n",
       " <xarray.Dataset>\n",
       " Dimensions:    (time: 853, latitude: 1, longitude: 1)\n",
       " Coordinates:\n",
       "   * latitude   (latitude) float64 28.12\n",
       "   * longitude  (longitude) float64 85.53\n",
       "   * time       (time) datetime64[ns] 1951-09-30 1951-10-31 ... 2022-09-30\n",
       " Data variables:\n",
       "     D          (time, latitude, longitude) datetime64[ns] 1951-09-30 ... 2022...\n",
       "     Q100       (time, latitude, longitude) float64 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
       "     year       (time, latitude, longitude) int64 1951 1951 1951 ... 2022 2022\n",
       "     month      (time, latitude, longitude) int64 9 10 11 12 1 2 ... 4 5 6 7 8 9,\n",
       " <xarray.Dataset>\n",
       " Dimensions:    (time: 853, latitude: 1, longitude: 1)\n",
       " Coordinates:\n",
       "   * latitude   (latitude) float64 28.12\n",
       "   * longitude  (longitude) float64 85.47\n",
       "   * time       (time) datetime64[ns] 1951-09-30 1951-10-31 ... 2022-09-30\n",
       " Data variables:\n",
       "     D          (time, latitude, longitude) datetime64[ns] 1951-09-30 ... 2022...\n",
       "     Q100       (time, latitude, longitude) float64 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
       "     year       (time, latitude, longitude) int64 1951 1951 1951 ... 2022 2022\n",
       "     month      (time, latitude, longitude) int64 9 10 11 12 1 2 ... 4 5 6 7 8 9,\n",
       " <xarray.Dataset>\n",
       " Dimensions:    (time: 853, latitude: 1, longitude: 1)\n",
       " Coordinates:\n",
       "   * latitude   (latitude) float64 28.07\n",
       "   * longitude  (longitude) float64 85.58\n",
       "   * time       (time) datetime64[ns] 1951-09-30 1951-10-31 ... 2022-09-30\n",
       " Data variables:\n",
       "     D          (time, latitude, longitude) datetime64[ns] 1951-09-30 ... 2022...\n",
       "     Q100       (time, latitude, longitude) float64 0.0 2.917e+04 ... 4.954e+04\n",
       "     year       (time, latitude, longitude) int64 1951 1951 1951 ... 2022 2022\n",
       "     month      (time, latitude, longitude) int64 9 10 11 12 1 2 ... 4 5 6 7 8 9,\n",
       " <xarray.Dataset>\n",
       " Dimensions:    (time: 853, latitude: 1, longitude: 1)\n",
       " Coordinates:\n",
       "   * latitude   (latitude) float64 28.07\n",
       "   * longitude  (longitude) float64 85.47\n",
       "   * time       (time) datetime64[ns] 1951-09-30 1951-10-31 ... 2022-09-30\n",
       " Data variables:\n",
       "     D          (time, latitude, longitude) datetime64[ns] 1951-09-30 ... 2022...\n",
       "     Q100       (time, latitude, longitude) float64 0.0 2.917e+04 ... 5.538e+04\n",
       "     year       (time, latitude, longitude) int64 1951 1951 1951 ... 2022 2022\n",
       "     month      (time, latitude, longitude) int64 9 10 11 12 1 2 ... 4 5 6 7 8 9,\n",
       " <xarray.Dataset>\n",
       " Dimensions:    (time: 853, latitude: 1, longitude: 1)\n",
       " Coordinates:\n",
       "   * latitude   (latitude) float64 28.12\n",
       "   * longitude  (longitude) float64 85.62\n",
       "   * time       (time) datetime64[ns] 1951-09-30 1951-10-31 ... 2022-09-30\n",
       " Data variables:\n",
       "     D          (time, latitude, longitude) datetime64[ns] 1951-09-30 ... 2022...\n",
       "     Q100       (time, latitude, longitude) float64 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
       "     year       (time, latitude, longitude) int64 1951 1951 1951 ... 2022 2022\n",
       "     month      (time, latitude, longitude) int64 9 10 11 12 1 2 ... 4 5 6 7 8 9,\n",
       " <xarray.Dataset>\n",
       " Dimensions:    (time: 853, latitude: 1, longitude: 1)\n",
       " Coordinates:\n",
       "   * latitude   (latitude) float64 28.12\n",
       "   * longitude  (longitude) float64 85.58\n",
       "   * time       (time) datetime64[ns] 1951-09-30 1951-10-31 ... 2022-09-30\n",
       " Data variables:\n",
       "     D          (time, latitude, longitude) datetime64[ns] 1951-09-30 ... 2022...\n",
       "     Q100       (time, latitude, longitude) float64 0.0 2.917e+04 ... 8.086e+04\n",
       "     year       (time, latitude, longitude) int64 1951 1951 1951 ... 2022 2022\n",
       "     month      (time, latitude, longitude) int64 9 10 11 12 1 2 ... 4 5 6 7 8 9,\n",
       " <xarray.Dataset>\n",
       " Dimensions:    (time: 853, latitude: 1, longitude: 1)\n",
       " Coordinates:\n",
       "   * latitude   (latitude) float64 28.07\n",
       "   * longitude  (longitude) float64 85.62\n",
       "   * time       (time) datetime64[ns] 1951-09-30 1951-10-31 ... 2022-09-30\n",
       " Data variables:\n",
       "     D          (time, latitude, longitude) datetime64[ns] 1951-09-30 ... 2022...\n",
       "     Q100       (time, latitude, longitude) float64 0.0 2.917e+04 ... 4.94e+04\n",
       "     year       (time, latitude, longitude) int64 1951 1951 1951 ... 2022 2022\n",
       "     month      (time, latitude, longitude) int64 9 10 11 12 1 2 ... 4 5 6 7 8 9]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11daffa-0730-4e4e-a2dd-39aab156d74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30bd9ff5-5aec-4790-95db-fc145041001e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<xarray.DataArray 'temperature' (t: 2)>\n",
       "  array([-0.97264916, -0.61886148])\n",
       "  Dimensions without coordinates: t,\n",
       "  <xarray.DataArray 'precipitation' (t: 2)>\n",
       "  array([0.21616394, 1.45705513])\n",
       "  Dimensions without coordinates: t]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = xr.DataArray(name=\"temperature\", data=np.random.randn(2), dims=[\"t\"])\n",
    "precip = xr.DataArray(name=\"precipitation\", data=np.random.randn(2), dims=[\"t\"])\n",
    "# ds_grid = [[temp, precip], [temp, precip]]\n",
    "ds_grid = [[temp, precip]]#, [temp, precip]]\n",
    "ds_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e04bf71-dace-499c-846e-88276dd9a407",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "concat_dims has length 3 but the datasets passed are nested in a 1-dimensional structure",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/31/xdyntby945q7564txk4rqyh40000gp/T/ipykernel_43930/958187477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/project1/lib/python3.7/site-packages/xarray/core/combine.py\u001b[0m in \u001b[0;36mcombine_nested\u001b[0;34m(datasets, concat_dim, compat, data_vars, coords, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0mcombine_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcombine_attrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m     )\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/project1/lib/python3.7/site-packages/xarray/core/combine.py\u001b[0m in \u001b[0;36m_nested_combine\u001b[0;34m(datasets, concat_dims, compat, data_vars, coords, ids, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0mcombine_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcombine_attrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     )\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/project1/lib/python3.7/site-packages/xarray/core/combine.py\u001b[0m in \u001b[0;36m_combine_nd\u001b[0;34m(combined_ids, concat_dims, data_vars, coords, compat, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"concat_dims has length {} but the datasets \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \"passed are nested in a {}-dimensional structure\".format(\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             )\n\u001b[1;32m    228\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: concat_dims has length 3 but the datasets passed are nested in a 1-dimensional structure"
     ]
    }
   ],
   "source": [
    "xr.combine_nested(datasets, concat_dim=['time', 'lat', 'lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673bc521-ac7b-4143-9f20-537d0b7db00d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472bd5e3-b17e-4fab-a25b-07a619f5a063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9891159a-cd5c-47cc-a3e0-c54c451cd522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f091e6f-7f89-48ef-bae6-de659bd8b61b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73437c5-66a1-4738-bb7b-aaad6be5553e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b25dff-afbf-47e8-a393-801acd1dcbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3524c0-f180-448b-950e-232a6a2bc79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e8a6de-19ba-44e8-ab94-39bfff817cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4254ff-061b-45cf-be8f-05e188a035c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a862ff-f72b-46a3-8708-2989ab8e741a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60e6fbb-512c-4ab7-892f-3920d61db3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['Longitude_new', 'Latitude_new', 'index', 'annual_mean_Qstl_mm', 'annual_25percent_Qstl_mm', 'annual_50percent_Qstl_mm', 'annual_75percent_Qstl_mm']\n",
    "\n",
    "langtang = pd.read_csv('/Users/varyabazilova/Desktop/paper2/202405_modelruns/1langtangTL/default_land_cover/default_land_coverlangtang_tl_percentiles_with_coords.csv')\n",
    "langtang = langtang.rename(columns = {'index': 'cellnr2'})\n",
    "langtang = langtang[['cellnr2', 'Latitude_new', 'Longitude_new']]\n",
    "# langtang = langtang.set_index('cellnr2')\n",
    "\n",
    "elevation = pd.read_csv('/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_and_elevation_with_labels_langtang.csv')[['cellnr2','band_data']]\n",
    "# elevation = elevation.set_index('cellnr2')\n",
    "\n",
    "langtang = langtang.merge(elevation, on = 'cellnr2')\n",
    "langtang = langtang.set_index('cellnr2')\n",
    "\n",
    "location_df = langtang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9e108-1edb-48e4-b809-64b0286fe399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e08eb0-5470-4103-99ef-0f0c951246e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c22d48d-ddcb-423d-84d8-09e2afdec4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "535dd7e4-ebf6-48f0-948b-572e0b8ec063",
   "metadata": {},
   "source": [
    "# create a datacube for mean monthly data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab2784b-9f83-4421-ad5e-c96b892e5b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the sediment csv \n",
    "# convert to xarray \n",
    "# add coordimates and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85330f1e-536f-4282-9759-9a8267d05514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langtang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe10e68a-9d04-470c-b332-278930aee608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dab325-ee0c-47e2-a3b8-7d5c03cc83f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read one sediment file \n",
    "pathSL = '/Users/varyabazilova/Desktop/paper2/202405_modelruns/xrds_test/'\n",
    "# Sed_mean = pd.read_csv(pathSL+ 'cellnr12a/Sediment.out')[['D', 'Q100']]\n",
    "\n",
    "# Sed_mean['D'] = pd.to_datetime(Sed_mean.D)\n",
    "# # extract id from the folder \n",
    "\n",
    "location_df = langtang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc922d-c5d3-4cda-81ef-0e6f28f5d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sed_mean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c43e76-5724-4cd8-9f8d-8e46dd43121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create xarray dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4606f8-712c-4d2f-8e93-58dcf12aaf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01425a02-6b67-48a1-b374-2aa265ae373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for folder_name in os.listdir(pathSL):\n",
    "    # skip dsstore thing\n",
    "    if folder_name == '.DS_Store':\n",
    "        continue\n",
    "    if folder_name == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    # skip all csvs\n",
    "    if folder_name.endswith('.csv'):\n",
    "        continue\n",
    "    print(folder_name)\n",
    "    # Extract location_id from the last 3 characters of the folder name\n",
    "    location_id = folder_name[-3:]\n",
    "\n",
    "    if location_id in location_df.index:\n",
    "        location_info = location_df.loc[location_id]\n",
    "        \n",
    "        elevation = location_info['band_data']\n",
    "        lat = location_info['Latitude_new']\n",
    "        lon = location_info['Longitude_new']\n",
    "\n",
    "        sediment_file = os.path.join(pathSL, folder_name, 'Sediment.out')\n",
    "        sediment_data = pd.read_csv(sediment_file)[['D', 'Q100']]\n",
    "        sediment_data['D'] = pd.to_datetime(sediment_data.D)\n",
    "\n",
    "          # Create xarray dataset\n",
    "        ds = xr.Dataset(\n",
    "            data_vars={col: (('time',), sediment_data[col]) for col in sediment_data.columns},\n",
    "            coords={'time': sediment_data['D'].values}\n",
    "        )\n",
    "\n",
    "        # Convert latitude and longitude coordinates to dimensions\n",
    "        ds_with_dims = ds.expand_dims({'latitude': [lat], 'longitude': [lon]}, axis=(1, 2))\n",
    "        datasets.append(ds_with_dims)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a7fc44-90cd-4f2c-abbc-e32cdc54aaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe886d-f927-4268-a3a9-5a13dc76e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Assuming datasets is a list containing your datasets\n",
    "\n",
    "# Extract latitude and longitude values from each dataset\n",
    "latitude_values = [ds['latitude'].data[0] for ds in datasets]\n",
    "longitude_values = [ds['longitude'].data[0] for ds in datasets]\n",
    "\n",
    "# Create DataArrays for latitude and longitude dimensions\n",
    "latitude_dim = xr.DataArray(latitude_values, dims='location')\n",
    "longitude_dim = xr.DataArray(longitude_values, dims='location')\n",
    "\n",
    "# Combine datasets along the time dimension\n",
    "combined_ds = xr.concat(datasets, dim='time')\n",
    "\n",
    "# Create a new dimension for latitude\n",
    "latitude_dim_combined = xr.DataArray(range(len(datasets)), dims='location')\n",
    "\n",
    "# Assign latitude and longitude as dimensions\n",
    "# combined_ds = combined_ds.assign_coords(latitude=(('location',), latitude_dim_combined),\n",
    "#                                         longitude=(('location',), longitude_dim))\n",
    "\n",
    "combined_ds = combined_ds.assign_coords(latitude=latitude_dim, longitude=longitude_dim)\n",
    "\n",
    "# Print the combined dataset\n",
    "combined_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe585dfb-c767-4c05-a762-2e06795e621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ds.isel(time = 100).Q100.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f0321-dc69-419b-9458-a677d178d566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a1ba5-6c4a-419f-8141-4c5e1fdbd27a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:project1]",
   "language": "python",
   "name": "conda-env-project1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
