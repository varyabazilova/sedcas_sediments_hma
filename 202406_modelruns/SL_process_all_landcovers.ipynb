{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00a46ac3-f921-4728-b92b-df9d01341b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "# import xycmap\n",
    "\n",
    "import functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9559c1-c8e6-40ab-97c9-a9d26cf9d85a",
   "metadata": {},
   "source": [
    "## 1  calculate annual mean per the 30-years of modelling for all land covers - langtang\n",
    "\n",
    "\n",
    "structure: \n",
    "- 4 different land covers\n",
    "- 3 different regions\n",
    "- this notebook is for langtang "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ed79b5f-9506-465b-bdf1-3b80c57fea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestep workaround\n",
    "column = 'Qstl'\n",
    "# Declare the landcover variable\n",
    "landcover = 'landcover4'\n",
    "\n",
    "\n",
    "# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/1landcover_mean/langtang_climate_cut'\n",
    "# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/2landcover_mean/langtang_climate_cut'\n",
    "# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/3landcover_mean/langtang_climate_cut'\n",
    "folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/4landcover_mean/langtang_climate_cut'\n",
    "\n",
    "# read one file to get the time-step\n",
    "df = functions.calculate_monthly_sediment_yield_all(pd.read_csv(folder_path + '/12a/Sediment.out'), column)\n",
    "df = df[['month', 'year']]\n",
    "\n",
    "# elevation langtang\n",
    "elevation = pd.read_csv('/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_and_elevation_with_labels_langtang.csv')[['cellnr2','band_data']] \n",
    "elevation = elevation.transpose()\n",
    "\n",
    "elevation_list = elevation.loc['cellnr2'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b05c863c-e608-4e51-97ff-5d761ded8ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qstl\n",
      "default land cover. monthly data: same\n",
      "landcover4\n",
      "CPU times: user 14 s, sys: 575 ms, total: 14.6 s\n",
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "column = 'Qstl'\n",
    "print(column)\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over the files in the folders\n",
    "for folder_name in os.listdir(folder_path):\n",
    "    # skip dsstore thing\n",
    "    if folder_name == '.DS_Store':\n",
    "        continue\n",
    "    # skip all csvs\n",
    "    if folder_name.endswith('.csv'):\n",
    "        continue\n",
    "    file_path = os.path.join(folder_path, folder_name, 'Sediment.out')\n",
    "    if os.path.isfile(file_path):\n",
    "        sediments = pd.read_csv(file_path)\n",
    "        # calculate mean monthly value for given column \n",
    "        output_df = functions.calculate_monthly_sediment_yield_all(sediments, column)\n",
    "        # take the column \n",
    "        name_column = output_df[column]\n",
    "        # rename the columns \n",
    "        column_name = f'{column}_{folder_name}'\n",
    "        result_df[column_name] = name_column\n",
    "        result_df.columns = [col[-3:] for col in result_df.columns]\n",
    "\n",
    "# result_df2 = result_df.transpose()\n",
    "\n",
    "result_df = result_df\n",
    "result_df = result_df[elevation_list]\n",
    "\n",
    "if elevation_list == result_df.columns.tolist():\n",
    "    print(\"default land cover. monthly data: same\")\n",
    "else:\n",
    "    print(\"not the same\")\n",
    "\n",
    "\n",
    "# # rename columns according the the elevation and merge with timestep \n",
    "# result_df.columns = elevation.loc['band_data']\n",
    "# result_df = pd.concat([df, result_df],axis=1)\n",
    "# result_df['land_cover'] = 'landcover1'\n",
    "# print(result_df.land_cover[1])\n",
    "# # result_df.to_csv(folder_path + '/monthly_sum_elevation_Qstl_landcover1.csv', index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Rename the columns according to the elevation and merge with timestep\n",
    "result_df.columns = elevation.loc['band_data']\n",
    "result_df = pd.concat([df, result_df], axis=1)\n",
    "# Add the land_cover column using the variable\n",
    "result_df['land_cover'] = landcover\n",
    "# Print the land_cover value for the second row\n",
    "print(result_df.land_cover[1])\n",
    "# Save the DataFrame to a CSV file, including the landcover variable in the filename\n",
    "result_df.to_csv(f'{folder_path}/monthly_sum_elevation_Qstl_{landcover}.csv', index=False)\n",
    "\n",
    "\n",
    "# create a dataframe with timestep and attach it to the monthly data dataframe\n",
    "\n",
    "monthly_data = result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d630847-705c-4db4-974e-2c5311d3125d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>4485.0</th>\n",
       "      <th>3734.0</th>\n",
       "      <th>4880.0</th>\n",
       "      <th>4847.0</th>\n",
       "      <th>3908.0</th>\n",
       "      <th>3756.0</th>\n",
       "      <th>4498.0</th>\n",
       "      <th>4933.0</th>\n",
       "      <th>...</th>\n",
       "      <th>5699.0</th>\n",
       "      <th>5384.0</th>\n",
       "      <th>5217.0</th>\n",
       "      <th>5870.0</th>\n",
       "      <th>5424.0</th>\n",
       "      <th>5763.0</th>\n",
       "      <th>6335.0</th>\n",
       "      <th>5859.0</th>\n",
       "      <th>5936.0</th>\n",
       "      <th>land_cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1989</td>\n",
       "      <td>36549.884546</td>\n",
       "      <td>35569.348978</td>\n",
       "      <td>37082.315978</td>\n",
       "      <td>37037.590715</td>\n",
       "      <td>17881.341366</td>\n",
       "      <td>17774.901175</td>\n",
       "      <td>18306.735009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>landcover1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>landcover1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>landcover1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>1989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>landcover1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>landcover1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>landcover1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>6</td>\n",
       "      <td>2022</td>\n",
       "      <td>51182.636461</td>\n",
       "      <td>85518.733017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15801.091907</td>\n",
       "      <td>15757.468525</td>\n",
       "      <td>31430.926195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>landcover1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>7</td>\n",
       "      <td>2022</td>\n",
       "      <td>130952.605805</td>\n",
       "      <td>130266.224177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64800.216428</td>\n",
       "      <td>64783.733417</td>\n",
       "      <td>64862.539880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>landcover1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>landcover1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>55383.649822</td>\n",
       "      <td>54726.514715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49536.749449</td>\n",
       "      <td>49404.909156</td>\n",
       "      <td>80863.455198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>landcover1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  year         4485.0         3734.0        4880.0        4847.0  \\\n",
       "0        9  1989   36549.884546   35569.348978  37082.315978  37037.590715   \n",
       "1       10  1989       0.000000       0.000000      0.000000      0.000000   \n",
       "2       11  1989       0.000000       0.000000      0.000000      0.000000   \n",
       "3       12  1989       0.000000       0.000000      0.000000      0.000000   \n",
       "4        1  1990       0.000000       0.000000      0.000000      0.000000   \n",
       "..     ...   ...            ...            ...           ...           ...   \n",
       "392      5  2022       0.000000       0.000000      0.000000      0.000000   \n",
       "393      6  2022   51182.636461   85518.733017      0.000000      0.000000   \n",
       "394      7  2022  130952.605805  130266.224177      0.000000      0.000000   \n",
       "395      8  2022       0.000000       0.000000      0.000000      0.000000   \n",
       "396      9  2022   55383.649822   54726.514715      0.000000      0.000000   \n",
       "\n",
       "           3908.0        3756.0        4498.0  4933.0  ...  5699.0  5384.0  \\\n",
       "0    17881.341366  17774.901175  18306.735009     0.0  ...     0.0     0.0   \n",
       "1        0.000000      0.000000      0.000000     0.0  ...     0.0     0.0   \n",
       "2        0.000000      0.000000      0.000000     0.0  ...     0.0     0.0   \n",
       "3        0.000000      0.000000      0.000000     0.0  ...     0.0     0.0   \n",
       "4        0.000000      0.000000      0.000000     0.0  ...     0.0     0.0   \n",
       "..            ...           ...           ...     ...  ...     ...     ...   \n",
       "392      0.000000      0.000000      0.000000     0.0  ...     0.0     0.0   \n",
       "393  15801.091907  15757.468525  31430.926195     0.0  ...     0.0     0.0   \n",
       "394  64800.216428  64783.733417  64862.539880     0.0  ...     0.0     0.0   \n",
       "395      0.000000      0.000000      0.000000     0.0  ...     0.0     0.0   \n",
       "396  49536.749449  49404.909156  80863.455198     0.0  ...     0.0     0.0   \n",
       "\n",
       "     5217.0  5870.0  5424.0  5763.0  6335.0  5859.0  5936.0  land_cover  \n",
       "0       0.0     0.0     0.0     0.0     0.0     0.0     0.0  landcover1  \n",
       "1       0.0     0.0     0.0     0.0     0.0     0.0     0.0  landcover1  \n",
       "2       0.0     0.0     0.0     0.0     0.0     0.0     0.0  landcover1  \n",
       "3       0.0     0.0     0.0     0.0     0.0     0.0     0.0  landcover1  \n",
       "4       0.0     0.0     0.0     0.0     0.0     0.0     0.0  landcover1  \n",
       "..      ...     ...     ...     ...     ...     ...     ...         ...  \n",
       "392     0.0     0.0     0.0     0.0     0.0     0.0     0.0  landcover1  \n",
       "393     0.0     0.0     0.0     0.0     0.0     0.0     0.0  landcover1  \n",
       "394     0.0     0.0     0.0     0.0     0.0     0.0     0.0  landcover1  \n",
       "395     0.0     0.0     0.0     0.0     0.0     0.0     0.0  landcover1  \n",
       "396     0.0     0.0     0.0     0.0     0.0     0.0     0.0  landcover1  \n",
       "\n",
       "[397 rows x 55 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58da48f-1c47-4d3d-b74f-7b4628463a2e",
   "metadata": {},
   "source": [
    "# 2 mean monthly (averaged across all the years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0a5b3c9-54df-4cd0-a802-b658116e6e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/1landcover/langtang_climate_cut'\n",
    "# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2landcover/langtang_climate_cut'\n",
    "# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/3landcover/langtang_climate_cut'\n",
    "# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/4landcover/langtang_climate_cut'\n",
    "\n",
    "landcover = 'landcover4'\n",
    "\n",
    "# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/1landcover_mean/langtang_climate_cut'\n",
    "# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/2landcover_mean/langtang_climate_cut'\n",
    "# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/3landcover_mean/langtang_climate_cut'\n",
    "folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/4landcover_mean/langtang_climate_cut'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2921a2b5-4262-47cb-a019-42b19d314327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qstl\n",
      "default land cover. monthly data: same\n",
      "landcover4\n",
      "CPU times: user 14.5 s, sys: 598 ms, total: 15.1 s\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "column = 'Qstl'\n",
    "print(column)\n",
    "monthly_mean = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Iterate over the files in the folders\n",
    "for folder_name in os.listdir(folder_path):\n",
    "    # skip dsstore thing\n",
    "    if folder_name == '.DS_Store':\n",
    "        continue\n",
    "    # skip all csvs\n",
    "    if folder_name.endswith('.csv'):\n",
    "        continue\n",
    "    file_path = os.path.join(folder_path, folder_name, 'Sediment.out')\n",
    "    if os.path.isfile(file_path):\n",
    "        \n",
    "        # calculate mean monthly value for given column \n",
    "        output_df = functions.calculate_monthly_sediment_yield(pd.read_csv(file_path))\n",
    "        # take the column \n",
    "        name_column = output_df[column]\n",
    "        # rename the columns \n",
    "        column_name = f'{column}_{folder_name}'\n",
    "        monthly_mean[column_name] = name_column\n",
    "        monthly_mean.columns = [col[-3:] for col in monthly_mean.columns]\n",
    "\n",
    "\n",
    "monthly_mean = monthly_mean[elevation_list]\n",
    "\n",
    "if elevation_list == monthly_mean.columns.tolist():\n",
    "    print(\"default land cover. monthly data: same\")\n",
    "else:\n",
    "    print(\"not the same\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "monthly_mean.columns = elevation.loc['band_data']\n",
    "# add month column\n",
    "monthly_mean['month'] = monthly_mean.index.values + 1\n",
    "monthly_mean['land_cover'] =landcover\n",
    "print(monthly_mean['land_cover'][1])\n",
    "# monthly_mean.to_csv(folder_path + '/long_term_mean_monthly_Qstl_elevation_{landcover}.csv', index = False)\n",
    "\n",
    "\n",
    "# monthly_mean.to_csv(f'{folder_path}/long_term_mean_monthly_Qstl_elevation_{landcover}.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658ab080-3319-43b0-9fdd-a65acc60f75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elevation_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2021d77b-c2b3-46f3-8592-f2a15ab6a11b",
   "metadata": {},
   "source": [
    "# 3 mustang - all months "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41916253-7799-43b8-9219-b543c6414046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestep workaround\n",
    "column = 'Qstl'\n",
    "\n",
    "landcover = 'landcover4'\n",
    "# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/1landcover_mean/mustang_climate_cut'\n",
    "# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/2landcover_mean/mustang_climate_cut'\n",
    "# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/3landcover_mean/mustang_climate_cut'\n",
    "folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/4landcover_mean/mustang_climate_cut'\n",
    "\n",
    "\n",
    "# read one file to get the time-step\n",
    "df = functions.calculate_monthly_sediment_yield_all(pd.read_csv(folder_path + '/13a/Sediment.out'), column)\n",
    "df = df[['month', 'year']]\n",
    "\n",
    "# elevation langtang\n",
    "elevation = pd.read_csv('/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_and_elevation_with_labels_mustang.csv')[['cellnr2','band_data']] \n",
    "elevation = elevation.transpose()\n",
    "\n",
    "elevation_list = elevation.loc['cellnr2'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13ccea92-6a97-41e2-a01e-c352c16890ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qstl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default land cover. monthly data: same\n",
      "landcover4\n",
      "CPU times: user 50.4 s, sys: 1.94 s, total: 52.3 s\n",
      "Wall time: 53.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "column = 'Qstl'\n",
    "print(column)\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over the files in the folders\n",
    "for folder_name in os.listdir(folder_path):\n",
    "    # skip dsstore thing\n",
    "    if folder_name == '.DS_Store':\n",
    "        continue\n",
    "    # skip all csvs\n",
    "    if folder_name.endswith('.csv'):\n",
    "        continue\n",
    "    file_path = os.path.join(folder_path, folder_name, 'Sediment.out')\n",
    "    if os.path.isfile(file_path):\n",
    "        sediments = pd.read_csv(file_path)\n",
    "        # calculate mean monthly value for given column \n",
    "        output_df = functions.calculate_monthly_sediment_yield_all(sediments, column)\n",
    "        # take the column \n",
    "        name_column = output_df[column]\n",
    "        # rename the columns \n",
    "        column_name = f'{column}_{folder_name}'\n",
    "        result_df[column_name] = name_column\n",
    "        result_df.columns = [col[-3:] for col in result_df.columns]\n",
    "\n",
    "# result_df2 = result_df.transpose()\n",
    "\n",
    "result_df = result_df\n",
    "result_df = result_df[elevation_list]\n",
    "\n",
    "if elevation_list == result_df.columns.tolist():\n",
    "    print(\"default land cover. monthly data: same\")\n",
    "else:\n",
    "    print(\"not the same\")\n",
    "\n",
    "\n",
    "# rename columns according the the elevation and merge with timestep \n",
    "result_df.columns = elevation.loc['band_data']\n",
    "result_df = pd.concat([df, result_df],axis=1)\n",
    "result_df['land_cover'] = landcover\n",
    "print(result_df.land_cover[1])\n",
    "# result_df.to_csv(folder_path + '/monthly_sum_elevation_Qstl_landcover4.csv', index = False)\n",
    "\n",
    "# create a dataframe with timestep and attach it to the monthly data dataframe\n",
    "\n",
    "# result_df.to_csv(f'{folder_path}/monthly_sum_elevation_Qstl_{landcover}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc21c58b-accf-455d-bb7b-567c4947e192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80250d64-33a4-418c-ba15-0fbc7e7cd930",
   "metadata": {},
   "source": [
    "# mustang - monthly average across years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db68c18f-d8d5-40af-ba77-aff630b2c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover = 'landcover3'\n",
    "\n",
    "# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/1landcover_mean/mustang_climate_cut'\n",
    "# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/2landcover_mean/mustang_climate_cut'\n",
    "folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/3landcover_mean/mustang_climate_cut'\n",
    "# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/4landcover_mean/mustang_climate_cut'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8fd244c6-b36f-475c-afa7-1688f971ddba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qstl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default land cover. monthly data: same\n",
      "landcover3\n",
      "CPU times: user 50.7 s, sys: 1.93 s, total: 52.6 s\n",
      "Wall time: 53.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "column = 'Qstl'\n",
    "print(column)\n",
    "monthly_mean = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Iterate over the files in the folders\n",
    "for folder_name in os.listdir(folder_path):\n",
    "    # skip dsstore thing\n",
    "    if folder_name == '.DS_Store':\n",
    "        continue\n",
    "    # skip all csvs\n",
    "    if folder_name.endswith('.csv'):\n",
    "        continue\n",
    "    file_path = os.path.join(folder_path, folder_name, 'Sediment.out')\n",
    "    if os.path.isfile(file_path):\n",
    "        \n",
    "        # calculate mean monthly value for given column \n",
    "        output_df = functions.calculate_monthly_sediment_yield(pd.read_csv(file_path))\n",
    "        # take the column \n",
    "        name_column = output_df[column]\n",
    "        # rename the columns \n",
    "        column_name = f'{column}_{folder_name}'\n",
    "        monthly_mean[column_name] = name_column\n",
    "        monthly_mean.columns = [col[-3:] for col in monthly_mean.columns]\n",
    "\n",
    "\n",
    "monthly_mean = monthly_mean[elevation_list]\n",
    "\n",
    "if elevation_list == monthly_mean.columns.tolist():\n",
    "    print(\"default land cover. monthly data: same\")\n",
    "else:\n",
    "    print(\"not the same\")\n",
    "\n",
    "\n",
    "\n",
    "monthly_mean.columns = elevation.loc['band_data']\n",
    "# add month column\n",
    "monthly_mean['month'] = monthly_mean.index.values + 1\n",
    "monthly_mean['land_cover'] = landcover\n",
    "print(monthly_mean['land_cover'][1])\n",
    "\n",
    "# monthly_mean.to_csv(folder_path + '/long_term_mean_monthly_Qstl_elevation_landcover4.csv', index = False)\n",
    "# monthly_mean.to_csv(f'{folder_path}/long_term_mean_monthly_Qstl_elevation_{landcover}.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac40d85e-9213-41a2-9be4-0be226349b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1936a1-90a2-49a1-a892-22962c39a9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b5b9c-41c8-4ab2-aa97-1819502b98f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42861bc8-93df-469b-baa2-c20f0ef9a4bf",
   "metadata": {},
   "source": [
    "# calculate mean annual values for all land covers for langtang and mustang areas forthe SL case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3861e93-8289-4cde-a856-29e5a6ddf38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# ----- LANGTANG -------\n",
    "\n",
    "# Path to the directory containing your folders\n",
    "# directory_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/1landcover/mustang_climate_cut'\n",
    "# directory_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2landcover/mustang_climate_cut'\n",
    "# directory_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/3landcover/mustang_climate_cut'\n",
    "directory_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/4landcover/langtang_climate_cut'\n",
    "\n",
    "mean_annual_sum =[]\n",
    "\n",
    "mean_annual_10 = []\n",
    "mean_annual_20 = []\n",
    "mean_annual_25 = []\n",
    "mean_annual_30 = []\n",
    "mean_annual_40 = []\n",
    "mean_annual_50 = []\n",
    "mean_annual_60 = []\n",
    "mean_annual_70 = []\n",
    "mean_annual_75 = []\n",
    "mean_annual_80 = []\n",
    "mean_annual_90 = []\n",
    "mean_annual_100 = []\n",
    "\n",
    "\n",
    "# Iterate over each folder\n",
    "for folder_name in os.listdir(directory_path):\n",
    "    folder_path = os.path.join(directory_path, folder_name)\n",
    "\n",
    "    if folder_name == '.DS_Store':\n",
    "        continue\n",
    "    if folder_name.startswith('.'):\n",
    "        continue\n",
    "    # skip all csvs\n",
    "    if folder_name.endswith('.csv'):\n",
    "        continue\n",
    "        \n",
    "    # Check if it's a directory and its name starts with 'cellnr'\n",
    "    if os.path.isdir(folder_path): #and folder_name.startswith('cellnr'):\n",
    "\n",
    "        # Locate the 'sediment.out' file within the folder\n",
    "        sediment_out_path = os.path.join(folder_path, 'Sediment.out')\n",
    "        \n",
    "        # Read the contents of the file into a pandas DataFrame\n",
    "        df = pd.read_csv(sediment_out_path, delimiter=',')  # Adjust delimiter if needed\n",
    "        # mean:\n",
    "        mean_annual_sum_value = functions.annual_sum_mean(df)\n",
    "        # percentiles:\n",
    "        mean_annual_10_value = functions.annual_sum_percentile(df, 10)\n",
    "        mean_annual_20_value = functions.annual_sum_percentile(df, 20)\n",
    "        mean_annual_25_value = functions.annual_sum_percentile(df, 25)\n",
    "        mean_annual_30_value = functions.annual_sum_percentile(df, 30)\n",
    "        mean_annual_40_value = functions.annual_sum_percentile(df, 40)\n",
    "        mean_annual_50_value = functions.annual_sum_percentile(df, 50)\n",
    "        mean_annual_60_value = functions.annual_sum_percentile(df, 60)\n",
    "        mean_annual_70_value = functions.annual_sum_percentile(df, 70)\n",
    "        mean_annual_75_value = functions.annual_sum_percentile(df, 75)\n",
    "        mean_annual_80_value = functions.annual_sum_percentile(df, 80)\n",
    "        mean_annual_90_value = functions.annual_sum_percentile(df, 90)\n",
    "        mean_annual_100_value =  functions.annual_sum_percentile(df, 100)\n",
    "\n",
    "       # # Save the DataFrame into the results table\n",
    "        mean_annual_sum.append((folder_name.replace('cellnr', ''), mean_annual_sum_value))\n",
    "\n",
    "        mean_annual_10.append((folder_name.replace('cellnr', ''), mean_annual_10_value ))\n",
    "        mean_annual_20.append((folder_name.replace('cellnr', ''), mean_annual_20_value ))\n",
    "        mean_annual_25.append((folder_name.replace('cellnr', ''), mean_annual_25_value ))\n",
    "        mean_annual_30.append((folder_name.replace('cellnr', ''), mean_annual_30_value ))\n",
    "        mean_annual_40.append((folder_name.replace('cellnr', ''), mean_annual_40_value ))\n",
    "        mean_annual_50.append((folder_name.replace('cellnr', ''), mean_annual_50_value ))\n",
    "        mean_annual_60.append((folder_name.replace('cellnr', ''), mean_annual_60_value ))\n",
    "        mean_annual_70.append((folder_name.replace('cellnr', ''), mean_annual_70_value ))\n",
    "        mean_annual_75.append((folder_name.replace('cellnr', ''), mean_annual_75_value ))\n",
    "        mean_annual_80.append((folder_name.replace('cellnr', ''), mean_annual_80_value ))\n",
    "        mean_annual_90.append((folder_name.replace('cellnr', ''), mean_annual_90_value ))\n",
    "        mean_annual_100.append((folder_name.replace('cellnr', ''),mean_annual_100_value))\n",
    "\n",
    "\n",
    "\n",
    "# make table \n",
    "mean_annual_sum_df = pd.DataFrame(mean_annual_sum, columns=['cellnr', 'annual_mean_Qstl_mm']).set_index('cellnr')\n",
    "mean_annual_10_df  = pd.DataFrame(mean_annual_10, columns=['cellnr', 'annual_10percent_Qstl_mm']).set_index('cellnr')\n",
    "mean_annual_20_df  = pd.DataFrame(mean_annual_20, columns=['cellnr', 'annual_20percent_Qstl_mm']).set_index('cellnr')\n",
    "mean_annual_25_df  = pd.DataFrame(mean_annual_25, columns=['cellnr', 'annual_25percent_Qstl_mm']).set_index('cellnr')\n",
    "mean_annual_30_df  = pd.DataFrame(mean_annual_30, columns=['cellnr', 'annual_30percent_Qstl_mm']).set_index('cellnr')\n",
    "mean_annual_40_df  = pd.DataFrame(mean_annual_40, columns=['cellnr', 'annual_40percent_Qstl_mm']).set_index('cellnr')\n",
    "mean_annual_50_df  = pd.DataFrame(mean_annual_50, columns=['cellnr', 'annual_50percent_Qstl_mm']).set_index('cellnr')\n",
    "mean_annual_60_df  = pd.DataFrame(mean_annual_60, columns=['cellnr', 'annual_60percent_Qstl_mm']).set_index('cellnr')\n",
    "mean_annual_70_df  = pd.DataFrame(mean_annual_70, columns=['cellnr', 'annual_70percent_Qstl_mm']).set_index('cellnr')\n",
    "mean_annual_75_df  = pd.DataFrame(mean_annual_75, columns=['cellnr', 'annual_75percent_Qstl_mm']).set_index('cellnr')\n",
    "mean_annual_80_df  = pd.DataFrame(mean_annual_80, columns=['cellnr', 'annual_80percent_Qstl_mm']).set_index('cellnr')\n",
    "mean_annual_90_df  = pd.DataFrame(mean_annual_90, columns=['cellnr', 'annual_90percent_Qstl_mm']).set_index('cellnr') \n",
    "mean_annual_100_df = pd.DataFrame(mean_annual_100, columns=['cellnr', 'annual_100percent_Qstl_mm']).set_index('cellnr')\n",
    "\n",
    "\n",
    "# merge together\n",
    "merged_df = pd.concat([mean_annual_sum_df, mean_annual_10_df, mean_annual_20_df,\n",
    "                       mean_annual_25_df, mean_annual_30_df, mean_annual_40_df, mean_annual_50_df,\n",
    "                       mean_annual_60_df, mean_annual_70_df, mean_annual_75_df, mean_annual_80_df, \n",
    "                       mean_annual_90_df, mean_annual_100_df], axis = 1)\n",
    "\n",
    "\n",
    "# merged_df.to_csv(directory_path + '/annual_mean_percentiles_for_sediment_input.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af130b-1bad-4433-82c9-0c577fb623a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to m3\n",
    "for column in merged_df.columns:\n",
    "    # for the columns with _mm in it\n",
    "    if '_mm' in column:\n",
    "        # Replace '_mm' with '_m3' and create a new column\n",
    "        new_column_name = column.replace('_mm', '_m3')\n",
    "        # convert to m3: 1) [sediments mm to m] 2) [sediments [m] * area [m2]\n",
    "        merged_df[new_column_name] = (merged_df[column] / 1000) * 4.83 * (10 ** 6)\n",
    "\n",
    "\n",
    "# calculate the volume of m3 per day \n",
    "\n",
    "for column in merged_df.columns:\n",
    "    if '_m3' in column:\n",
    "        merged_df[column + '_day'] = merged_df[column] /365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f83af4-5587-4c7c-a34c-af434e5fc9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add coordinates and save the output \n",
    "\n",
    "# csv with coordinates and geopotential (z) \n",
    "\n",
    "coordinates = pd.read_csv('/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_with_labels_langtang.csv').set_index('cellnr2')\n",
    "# coordinates = pd.read_csv('/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_with_labels_bagrot.csv').set_index('cellnr2')\n",
    "\n",
    "# coordinates = pd.read_csv('/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_with_labels_mustang.csv').set_index('cellnr2')\n",
    "with_coords = pd.concat([merged_df, coordinates],  axis=1).reset_index()\n",
    "# coordinates\n",
    "\n",
    "# with_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53da0974-347c-4ec7-ad23-b67dda1ee657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with_coords.to_csv(directory_path + '/annual_mean_percentiles_for_sediment_input.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1334ba22-b50f-48c3-a18f-10dc6a1c05cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a52dca0-95f8-405f-af2f-792784f4cbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sedcas] *",
   "language": "python",
   "name": "conda-env-sedcas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
