import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os 
import functions





# the data is stored on the external ssd 
# the output should go to the local folder 




%%time

landcover_idx = 1
location = 'langtang'
landcover = f'landcover{landcover_idx}'

column = 'dfs'

# path to data
folder_path = f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_once/{landcover_idx}landcover_25percent/{location}_climate_cut'

elevation = pd.read_csv(f'/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_and_elevation_with_labels_{location}.csv')[['cellnr2','band_data']] 

result_df = pd.DataFrame()


# Iterate over the files in the folders
for folder_name in os.listdir(folder_path):
    # skip all csvs and . files
    if folder_name.endswith('.csv'):
        continue
    if folder_name.startswith('.'):
        continue 
    
    file_path = os.path.join(folder_path, folder_name, 'Sediment.out') #create a path to file 
    
    if os.path.isfile(file_path): #check if its there 
        # read file 
        output_df = pd.read_csv(file_path)
        # count dfs per given time 
        output_df = functions.count_dfs_per_time(output_df, column, 'year')
        
        # take the COUNT column 
        name_column = output_df['count']
        # rename the columns 
        column_name = f'{column}_{folder_name}'
        result_df[column_name] = name_column
        result_df.columns = [col[-3:] for col in result_df.columns]


annaul_df_count = functions.add_elevation_to_df_count(result_df, elevation)


output_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_once/output_25percent/'
# annaul_df_count.to_csv(output_path + f'{location}_annual_df_count_annualmean_{landcover}.csv')










