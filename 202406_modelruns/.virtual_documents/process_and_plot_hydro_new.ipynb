# plan

# - caclulate monthly Q for different land covers 
# - calculate how on average change in lang cover affect the change in runoff -> transport capacity -> TL case 



# plan
# 1 - calculate the monthly water yeild 
# 2 - plot average + spread per month 



import pandas as pd 
import xarray as xr
import matplotlib.pyplot as plt 
import numpy as np
import os
import seaborn as sns


import functions







def water_balance_components_in_mm(hydro, column, area=4830.0):
    """
    Calculate the sum of water or sediment volume per month for a specific column, 
    and return the mean volumes across years.
    
    Parameters:
    hydro (pd.DataFrame): Input DataFrame with columns `D` (date) and the specified numeric column.
    column (str): The name of the column to calculate the volume for.
    area (float): Area in square meters used to scale the volumes. Default is 4830.0.
    
    Returns:
    pd.DataFrame: DataFrame with the calculated monthly volumes.
    """
    # Ensure `D` column is in datetime format
    hydro['D'] = pd.to_datetime(hydro['D'])

    if column == 'snowmelt':
        hydro['snowmelt'] = hydro['snowacc'].where(hydro['snowacc'] < 0).fillna(0)
    if column == 'snowacc2':
        hydro['snowacc2'] = hydro['snowacc'].where(hydro['snowacc'] > 0).fillna(0)
    if column == 'rainfall':
        hydro['rainfall'] = hydro['Pr'] - hydro['snowacc']
        hydro['rainfall'] = hydro['rainfall'].fillna(0)
        
    
    # Scale the specified column by the area
    hydro[column] = hydro[[column]]
    
    # Set 'D' as the index
    hydro = hydro.set_index('D')
    
    # Resample to monthly data and calculate the sum for each month for the specified column
    hydro_month = hydro[column].resample('M').sum().reset_index()
    
    # Extract year and month for grouping or further analysis
    hydro_month['year'] = hydro_month['D'].dt.year
    hydro_month['month'] = hydro_month['D'].dt.month
    
    return hydro_month



# folders = '/Volumes/6382452/!Feb2024/paper2/model_runs/TL_data/1landcover/langtang_climate_cut'





%%time

# column = 'Pr'  # Set the target column
location = 'mustang'

if location == 'langtang':
    folder_loc = '12a'
if location == 'mustang': 
    folder_loc = '13a'



# landcover1_folder = f'/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/TL_data/1landcover/{location}_climate_cut'
# landcover2_folder = f'/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/TL_data/2landcover/{location}_climate_cut'
# landcover3_folder = f'/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/TL_data/1landcover/{location}_climate_cut'
# landcover4_folder = f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_daily/1landcover_40percent/{location}_climate_cut' #this one is different - no change in glacier 
# landcover5_folder = f'/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/TL_data/5landcover/{location}_climate_cut'





output_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/output/hydro'

# Define the list of folder paths

folder_paths = [f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_daily/1landcover_30percent/{location}_climate_cut',
                f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_daily/2landcover_30percent/{location}_climate_cut',
                f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_daily/3landcover_30percent/{location}_climate_cut',
                f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_daily/4landcover_30percent/{location}_climate_cut',
                f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_daily/5landcover_30percent/{location}_climate_cut']





# Load elevation data and define the output path
elevation = pd.read_csv(f'/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_and_elevation_with_labels_{location}.csv')[['cellnr2', 'band_data']]
elevation = elevation.transpose()
elevation_list = elevation.loc['cellnr2'].tolist() 



# loop over columns too 
# columns = ['PET', 'AET', 'Q', 'snowacc2', 'snowmelt', 'glacier_melt', 'Pr', 'rainfall']
# columns = ['Pr', 'rainfall']


'''
%%time
print(columns)  # Ensure `columns` is defined as a list of column names

# Iterate over columns
for column in columns:
    print(f"Processing column: {column}")

    # Iterate over folder paths
    for folder_path in folder_paths:
        print(f"Processing folder: {folder_path}")

        output_folder = output_path

        # Extract "1landcover" from the folder path
        landcover_part = os.path.basename(os.path.dirname(folder_path))
        landcover_base = landcover_part.split('_')[0]  # This gives "1landcover"

        # Load timestep DataFrame (assuming Hydro.out exists in the `/12a/` subfolder for all folders)
        hydro_path = os.path.join(folder_path, folder_loc, 'Hydro.out')
        print(f"Checking Hydro.out path: {hydro_path}")

        if not os.path.isfile(hydro_path):
            print(f"Hydro.out not found in {hydro_path}")
            continue  # Skip this folder_path if the main Hydro.out is missing

        # Load the Hydro.out file for timestep calculation
        try:
            dfts = pd.read_csv(hydro_path)
            df = water_balance_components_in_mm(dfts, column, area=4830.0)
            df = df[['month', 'year']]
        except Exception as e:
            print(f"Error loading timestep file: {e}")
            continue

        # Initialize the result DataFrame for this folder_path
        result_df = pd.DataFrame()

        # Iterate over subfolders in the folder path
        for folder_name in os.listdir(folder_path):
            subfolder_path = os.path.join(folder_path, folder_name)
            
            # Skip files and hidden folders
            if not os.path.isdir(subfolder_path) or folder_name.startswith('.'):
                continue

            file_path = os.path.join(subfolder_path, 'Hydro.out')
            # print(f"Checking subfolder Hydro.out: {file_path}")

            # Ensure the Hydro.out file exists in the subfolder
            if os.path.isfile(file_path):
                try:
                    hydro = pd.read_csv(file_path)
                    output_df = water_balance_components_in_mm(hydro, column)

                    # Extract and rename the target column
                    name_column = output_df[column]
                    column_name = f'{column}_{folder_name}'
                    result_df[column_name] = name_column
                except Exception as e:
                    print(f"Error processing file {file_path}: {e}")
                    continue

        # Ensure result_df has data before proceeding
        if result_df.empty:
            print(f"No valid data found in subfolders of {folder_path}")
            continue

        # Rename columns for clarity and filter by elevation list
        result_df.columns = [col[-3:] for col in result_df.columns]  # Adjust column names if necessary
        result_df = result_df[elevation_list]

        # Check for consistency with the elevation list
        if elevation_list == result_df.columns.tolist():
            print("Default land cover. Monthly data: same")

            # Rename columns, merge with timestep, and add folder info
            result_df.columns = elevation.loc['band_data']
            result_df = pd.concat([df, result_df], axis=1)
            result_df['folder'] = os.path.basename(folder_path)

            print(result_df)

            # Define the output file name and save the DataFrame to a CSV file
            output_filename = f'{location}_monthly_sum_elevation_{column}_{landcover_base}_mm.csv'
            print('output filename:', output_filename)
            result_df.to_csv(os.path.join(output_folder, output_filename), index=False)

            print(f"Saved {output_filename}")
        else:
            print(f"The data does not match the elevation list for {folder_path}!")
'''


























# plot of interest: 
# barplots with + and - components 
# components:
# AET PET Q GLACIER_MELT SNOW_MELT SNOW_ACC 

# + Pr, snow melt, glacier melt
# - AET PET Q 


def prepare_for_boxplots(df, value_name):
    # value name - column in the output dataframe
    melted = pd.melt(df, id_vars=['month','folder', 'year'], var_name='elevation', value_name=value_name)
    melted['elevation'] = melted['elevation'].str.split('.').str[0].astype(float)
    melted['elevation_bin'] = melted.apply(functions.bin_elevation500, axis=1)
    melted = melted.sort_values('elevation_bin')
    return melted


# test for landcover 1
landcover_idx = 1
location = 'langtang' # 'mustang'

folder = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/output/hydro/'

aet1      = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_AET_{landcover_idx}landcover_mm.csv')
pet1      = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_PET_{landcover_idx}landcover_mm.csv')
Q1        = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_Q_{landcover_idx}landcover_mm.csv')
glmelt1   = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_glacier_melt_{landcover_idx}landcover_mm.csv')
snowmelt1 = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_snowmelt_{landcover_idx}landcover_mm.csv')
pr1       = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_Pr_{landcover_idx}landcover_mm.csv')
rainfall1 = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_rainfall_{landcover_idx}landcover_mm.csv')
snowacc1  = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_snowacc2_{landcover_idx}landcover_mm.csv')
rainfall1 = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_rainfall_{landcover_idx}landcover_mm.csv')


# mustang_monthly_sum_elevation_Pr_1landcover_mm
# mustang_monthly_sum_elevation_snowacc2_2landcover_mm





aet1_melted = prepare_for_boxplots(aet1, 'AET')
pet1_melted = prepare_for_boxplots(pet1, 'PET')
Q1_melted = prepare_for_boxplots(Q1, 'Q')

glmelt1_melted = prepare_for_boxplots(glmelt1, 'glmelt')
snowmelt1_melted = prepare_for_boxplots(snowmelt1, 'snowmelt')
pr1_melted = prepare_for_boxplots(pr1, 'Pr')
rainfall1_melted = prepare_for_boxplots(rainfall1, 'Pr')
snowacc1_melted = prepare_for_boxplots(snowacc1, 'snowacc')


# make snowmelt not negative 
snowmelt1_melted['snowmelt'] = snowmelt1_melted['snowmelt'] * -1



fig = plt.figure(figsize=(20, 20), layout = 'tight')
mosaic = fig.subplot_mosaic('''
                            aaa
                            bbb
                            ccc
                            eee
                            fff
                            ggg
                            ''')


sns.barplot(ax = mosaic['a'], x='month', y='Pr', hue = 'elevation_bin', data=pr1_melted, palette = 'magma_r', legend = True) 
sns.barplot(ax = mosaic['b'], x='month', y='AET', hue = 'elevation_bin', data=aet1_melted, palette = 'viridis_r', legend = False) 
sns.barplot(ax = mosaic['c'], x='month', y='PET', hue = 'elevation_bin', data=pet1_melted, palette = 'viridis_r', legend = True)
# sns.barplot(ax = mosaic['d'], x='month', y='snowacc', hue = 'elevation_bin', data=snowacc1_melted, palette = 'magma_r', legend = False)
sns.barplot(ax = mosaic['e'], x='month', y='snowmelt', hue = 'elevation_bin', data=snowmelt1_melted, palette = 'magma_r', legend = False)
sns.barplot(ax = mosaic['f'], x='month', y='glmelt', hue = 'elevation_bin', data=glmelt1_melted, palette = 'magma_r', legend = False)
sns.barplot(ax = mosaic['g'], x='month', y='Q', hue = 'elevation_bin', data=Q1_melted, palette = 'magma_r', legend = False)


sns.move_legend(mosaic['a'], "upper left", bbox_to_anchor=(1, 1))
sns.move_legend(mosaic['c'], "upper left", bbox_to_anchor=(1, 1))

# # Adding text to the top-left corner of each subplot
# mosaic['a'].text(0.02, 0.95, 'veg 40%, bedrock 40%, ice 20%', transform=mosaic['a'].transAxes, fontsize=25, verticalalignment='top')
# mosaic['b'].text(0.02, 0.95, 'veg 40%, bedrock 50%, ice 10%', transform=mosaic['b'].transAxes, fontsize=25, verticalalignment='top')
# mosaic['c'].text(0.02, 0.95, 'veg 50%, bedrock 40%, ice 10%', transform=mosaic['c'].transAxes, fontsize=25, verticalalignment='top')
# mosaic['d'].text(0.02, 0.95, 'veg 40%, bedrock 60%, ice 0%',  transform=mosaic['d'].transAxes, fontsize=25, verticalalignment='top')





if landcover_idx ==1:
    plt.suptitle('veg 40%, bedrock 40%, ice 20%', fontsize = 25)
if landcover_idx ==2:
    plt.suptitle('veg 40%, bedrock 50%, ice 10%', fontsize = 25)
if landcover_idx ==3:
    plt.suptitle('veg 50%, bedrock 40%, ice 10%', fontsize = 25)







# List of components (example structure)
wb_components = [aet1_melted, pet1_melted, Q1_melted, glmelt1_melted, snowmelt1_melted, 
                 pr1_melted, snowacc1_melted]


grouped_dfs = []

# Iterate over each component, group by 'month', and compute the mean
for c in wb_components:
    grouped = c.groupby('month').mean().drop(columns=['elevation', 'year'])
    # Add a suffix to the column names to indicate the source DataFrame
    grouped = grouped.add_suffix(f'_lc{landcover_idx}')
    grouped_dfs.append(grouped)

# Concatenate all grouped DataFrames along the columns
result_df = pd.concat(grouped_dfs, axis=1)

# result_df.to_csv(folder + f'wb_components_monthly_mean_{location}_landcover{landcover_idx}.csv')


wb1 = pd.read_csv(folder + f'wb_components_monthly_mean_langtang_landcover1.csv', index_col = 0)
wb2 = pd.read_csv(folder + f'wb_components_monthly_mean_langtang_landcover2.csv', index_col = 0)
wb3 = pd.read_csv(folder + f'wb_components_monthly_mean_langtang_landcover3.csv', index_col = 0)
wb4 = pd.read_csv(folder + f'wb_components_monthly_mean_langtang_landcover4.csv', index_col = 0)
wb5 = pd.read_csv(folder + f'wb_components_monthly_mean_langtang_landcover5.csv', index_col = 0)







fig = plt.figure(figsize=(20, 15), layout = 'tight')
mosaic = fig.subplot_mosaic('''
                            ab
                            cd
                            ef
                            ''')

wb1[['glmelt_lc1', 'snowmelt_lc1', 'Pr_lc1']].plot(ax = mosaic['a'], kind = 'bar', stacked = True, cmap = 'Set2')
wb2[['glmelt_lc2', 'snowmelt_lc2', 'Pr_lc2']].plot(ax = mosaic['b'], kind = 'bar', stacked = True, cmap = 'magma')
wb3[['glmelt_lc3', 'snowmelt_lc3', 'Pr_lc3']].plot(ax = mosaic['c'], kind = 'bar', stacked = True, cmap = 'magma')
wb4[['glmelt_lc4', 'snowmelt_lc4', 'Pr_lc4']].plot(ax = mosaic['d'], kind = 'bar', stacked = True, cmap = 'magma')
wb5[['glmelt_lc5', 'snowmelt_lc5', 'Pr_lc5']].plot(ax = mosaic['e'], kind = 'bar', stacked = True, cmap = 'magma')

wb1[['Q_lc1']].plot(ax = mosaic['a'], kind = 'line')
wb1[['AET_lc1']].plot(ax = mosaic['a'], kind = 'line', stacked = True, cmap = 'Set2')



# plot so that left column is the dischange and precipitation and temperature 
# right plot is the stacked water balance components - maybe in the % of the dischsnge?
# right plot: IN components - positive, OUT components - negative 


# 'Q'
# IN: 'glmelt_lc1', 'snowmelt_lc1', 'Pr_lc1'
# OUT: 'AET_lc1', 'Q'
# PET_lc1 -? where does that go


# wb1.columnsPET_lc1





# test for landcover 1
landcover_idx = 5
location = 'langtang' # 'mustang'

folder = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/output/hydro/'

aet      = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_AET_{landcover_idx}landcover_mm.csv')
pet      = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_PET_{landcover_idx}landcover_mm.csv')
Q        = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_Q_{landcover_idx}landcover_mm.csv')
glmelt   = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_glacier_melt_{landcover_idx}landcover_mm.csv')
snowmelt = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_snowmelt_{landcover_idx}landcover_mm.csv')
pr       = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_Pr_{landcover_idx}landcover_mm.csv')
rainfall = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_rainfall_{landcover_idx}landcover_mm.csv')
snowacc  = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_snowacc2_{landcover_idx}landcover_mm.csv')
rainfall = pd.read_csv(folder+location+'/'+ f'{location}_monthly_sum_elevation_rainfall_{landcover_idx}landcover_mm.csv')



# calculate mean annual per column and then average out in space (for all elevations)
def mean_annual_for_all_locations(df):
    grouped = df.groupby('year').sum().iloc[1:-1]
    grouped = grouped.drop(columns = 'month')
    # test = test.iloc[1:-1]
    final = grouped.T.mean()
    return final


snowmelt[snowmelt.select_dtypes(include='number').columns] = snowmelt.select_dtypes(include='number').applymap(
    lambda x: -x if x < 0 else x)




# Assuming 'wb_components' is a list of dataframes, and each dataframe has a 'year' column
wb_components = [aet, pet, Q, glmelt, snowmelt, pr, snowacc]
wb_names = ['aet', 'pet', 'Q', 'glmelt', 'snowmelt', 'pr', 'snowacc']  # Corresponding names

# Initialize an empty dictionary to store results
results = {}

# Iterate over the dataframes and names
for df, name in zip(wb_components, wb_names):
    results[name] = mean_annual_for_all_locations(df)

# Combine the results into a final dataframe
final_df = pd.DataFrame(results)


# final_df.to_csv(folder + f'wb_components_annual_mean_{location}_landcover{landcover_idx}.csv', index = True)






annual1 = pd.read_csv(folder + f'wb_components_annual_mean_{location}_landcover1.csv', index_col = 0)#.rename(columns = {'0':'value'}).set_index('index')
annual2 = pd.read_csv(folder + f'wb_components_annual_mean_{location}_landcover2.csv', index_col = 0)#.rename(columns = {'0':'value'}).set_index('index')
annual3 = pd.read_csv(folder + f'wb_components_annual_mean_{location}_landcover3.csv', index_col = 0)#.rename(columns = {'0':'value'}).set_index('index')
annual4 = pd.read_csv(folder + f'wb_components_annual_mean_{location}_landcover4.csv', index_col = 0)#.rename(columns = {'0':'value'}).set_index('index')
annual5 = pd.read_csv(folder + f'wb_components_annual_mean_{location}_landcover5.csv', index_col = 0)#.rename(columns = {'0':'value'}).set_index('index')


annual1T = annual1.mean().T
annual1T['rainfall'] = annual1T.pr - annual1T.snowmelt
annual1T


annual2T = annual2.mean().T
annual2T['rainfall'] = annual2T.pr - annual2T.snowmelt
annual2T


annual3T = annual3.mean().T
annual3T['rainfall'] = annual3T.pr - annual3T.snowmelt
annual3T


annual4T = annual4.mean().T
annual4T['rainfall'] = annual4T.pr - annual4T.snowmelt
annual4T


annual5T = annual5.mean().T
annual5T['rainfall'] = annual5T.pr - annual5T.snowmelt
annual5T














annual1T.plot(kind = 'bar')
annual2T.plot(kind = 'bar')
annual3T.plot(kind = 'bar')





# total_out = Q + AET + GW sink

# total_in = Pr + gl melt 

total_out = annual1T.Q_lc1[0] + annual1T.AET_lc1[0] # + whatever is left in the difference 

total_in = annual1T.Pr_lc1[0] + annual1T.glmelt_lc1[0] + annual1T.snowmelt_lc1[0]


annual1T.Pr_lc1[0] - annual1T.snowmelt_lc1[0]


total_in


wblc1 = {
    'Source': ['Pr', 'Pr', 'Glacier Melt', 'Glacier Melt'],
    'Target': ['AET',  'Q', 'AET', 'Q', 'Storage change'],
    'Value': [60, 40, 20, 30]
}



