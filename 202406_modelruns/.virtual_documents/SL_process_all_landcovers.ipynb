import pandas as pd 
import xarray as xr
import matplotlib.pyplot as plt 
import numpy as np
import os
import seaborn as sns

# import xycmap

import functions






# timestep workaround
column = 'Q100'
# Declare the landcover variable
landcover = 'landcover4'


# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/1landcover_mean/langtang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/2landcover_mean/langtang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/3landcover_mean/langtang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/4landcover_mean/langtang_climate_cut'

# 
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/1landcover_25percent/langtang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/2landcover_25percent/langtang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/3landcover_25percent/langtang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/4landcover_25percent/langtang_climate_cut'



# read one file to get the time-step
df = functions.calculate_monthly_sediment_yield_all(pd.read_csv(folder_path + '/12a/Sediment.out'), column)
df = df[['month', 'year']]

# elevation langtang
elevation = pd.read_csv('/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_and_elevation_with_labels_langtang.csv')[['cellnr2','band_data']] 
elevation = elevation.transpose()

elevation_list = elevation.loc['cellnr2'].tolist()



%%time

column = 'Q100'
print(column)
result_df = pd.DataFrame()

# Iterate over the files in the folders
for folder_name in os.listdir(folder_path):
    # skip dsstore thing
    if folder_name == '.DS_Store':
        continue
    # skip all csvs
    if folder_name.endswith('.csv'):
        continue
    file_path = os.path.join(folder_path, folder_name, 'Sediment.out')
    if os.path.isfile(file_path):
        sediments = pd.read_csv(file_path)
        # calculate mean monthly value for given column 
        output_df = functions.calculate_monthly_sediment_yield_all(sediments, column)
        # take the column 
        name_column = output_df[column]
        # rename the columns 
        column_name = f'{column}_{folder_name}'
        result_df[column_name] = name_column
        result_df.columns = [col[-3:] for col in result_df.columns]

# result_df2 = result_df.transpose()

result_df = result_df
result_df = result_df[elevation_list]

if elevation_list == result_df.columns.tolist():
    print("default land cover. monthly data: same")
else:
    print("not the same")


# # rename columns according the the elevation and merge with timestep 
# result_df.columns = elevation.loc['band_data']
# result_df = pd.concat([df, result_df],axis=1)
# result_df['land_cover'] = 'landcover1'
# print(result_df.land_cover[1])
# # result_df.to_csv(folder_path + '/monthly_sum_elevation_Qstl_landcover1.csv', index = False)






# Rename the columns according to the elevation and merge with timestep
result_df.columns = elevation.loc['band_data']
result_df = pd.concat([df, result_df], axis=1)
# Add the land_cover column using the variable
result_df['land_cover'] = landcover
# Print the land_cover value for the second row
print(result_df.land_cover[1])
# Save the DataFrame to a CSV file, including the landcover variable in the filename
result_df.to_csv(f'{folder_path}/monthly_sum_elevation_Qstl_{landcover}.csv', index=False)


# create a dataframe with timestep and attach it to the monthly data dataframe

monthly_data = result_df


# result_df





landcover = 'landcover4'

# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/1landcover_25percent/langtang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/2landcover_25percent/langtang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/3landcover_25percent/langtang_climate_cut'
folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/4landcover_25percent/langtang_climate_cut'





%%time

# column = 'Q100'
print(column)
monthly_mean = pd.DataFrame()


# Iterate over the files in the folders
for folder_name in os.listdir(folder_path):
    # skip dsstore thing
    if folder_name == '.DS_Store':
        continue
    # skip all csvs
    if folder_name.endswith('.csv'):
        continue
    file_path = os.path.join(folder_path, folder_name, 'Sediment.out')
    if os.path.isfile(file_path):
        
        # calculate mean monthly value for given column 
        output_df = functions.calculate_monthly_sediment_yield(pd.read_csv(file_path))
        # take the column 
        name_column = output_df[column]
        # rename the columns 
        column_name = f'{column}_{folder_name}'
        monthly_mean[column_name] = name_column
        monthly_mean.columns = [col[-3:] for col in monthly_mean.columns]


monthly_mean = monthly_mean[elevation_list]

if elevation_list == monthly_mean.columns.tolist():
    print("default land cover. monthly data: same")
else:
    print("not the same")




monthly_mean.columns = elevation.loc['band_data']
# add month column
monthly_mean['month'] = monthly_mean.index.values + 1
monthly_mean['land_cover'] =landcover
print(monthly_mean['land_cover'][1])
# monthly_mean.to_csv(folder_path + '/long_term_mean_monthly_Qstl_elevation_{landcover}.csv', index = False)


monthly_mean.to_csv(f'{folder_path}/long_term_mean_monthly_Qstl_elevation_{landcover}.csv', index=False)





# elevation_list








# timestep workaround
# column = 'Qstl'

landcover = 'landcover4'

# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/1landcover_mean/mustang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/2landcover_mean/mustang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/3landcover_mean/mustang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/4landcover_mean/mustang_climate_cut'

# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/1landcover_25percent/mustang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/2landcover_25percent/mustang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/3landcover_25percent/mustang_climate_cut'
folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/4landcover_25percent/mustang_climate_cut'






# read one file to get the time-step
df = functions.calculate_monthly_sediment_yield_all(pd.read_csv(folder_path + '/13a/Sediment.out'), column)
df = df[['month', 'year']]

# elevation langtang
elevation = pd.read_csv('/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_and_elevation_with_labels_mustang.csv')[['cellnr2','band_data']] 
elevation = elevation.transpose()

elevation_list = elevation.loc['cellnr2'].tolist()



%%time

# column = 'Qstl'
print(column)
result_df = pd.DataFrame()

# Iterate over the files in the folders
for folder_name in os.listdir(folder_path):
    # skip dsstore thing
    if folder_name == '.DS_Store':
        continue
    # skip all csvs
    if folder_name.endswith('.csv'):
        continue
    file_path = os.path.join(folder_path, folder_name, 'Sediment.out')
    if os.path.isfile(file_path):
        sediments = pd.read_csv(file_path)
        # calculate mean monthly value for given column 
        output_df = functions.calculate_monthly_sediment_yield_all(sediments, column)
        # take the column 
        name_column = output_df[column]
        # rename the columns 
        column_name = f'{column}_{folder_name}'
        result_df[column_name] = name_column
        result_df.columns = [col[-3:] for col in result_df.columns]

# result_df2 = result_df.transpose()

result_df = result_df
result_df = result_df[elevation_list]

if elevation_list == result_df.columns.tolist():
    print("default land cover. monthly data: same")
else:
    print("not the same")


# rename columns according the the elevation and merge with timestep 
result_df.columns = elevation.loc['band_data']
result_df = pd.concat([df, result_df],axis=1)
result_df['land_cover'] = landcover
print(result_df.land_cover[1])
# result_df.to_csv(folder_path + '/monthly_sum_elevation_Qstl_landcover4.csv', index = False)

# create a dataframe with timestep and attach it to the monthly data dataframe

result_df.to_csv(f'{folder_path}/monthly_sum_elevation_Qstl_{landcover}.csv', index=False)









landcover = 'landcover4'

# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/1landcover_mean/mustang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/2landcover_mean/mustang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/3landcover_mean/mustang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/4landcover_mean/mustang_climate_cut'


# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/1landcover_25percent/mustang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/2landcover_25percent/mustang_climate_cut'
# folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/3landcover_25percent/mustang_climate_cut'
folder_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_daily/4landcover_25percent/mustang_climate_cut'





%%time

# column = 'Qstl'
print(column)
monthly_mean = pd.DataFrame()


# Iterate over the files in the folders
for folder_name in os.listdir(folder_path):
    # skip dsstore thing
    if folder_name == '.DS_Store':
        continue
    # skip all csvs
    if folder_name.endswith('.csv'):
        continue
    file_path = os.path.join(folder_path, folder_name, 'Sediment.out')
    if os.path.isfile(file_path):
        
        # calculate mean monthly value for given column 
        output_df = functions.calculate_monthly_sediment_yield(pd.read_csv(file_path))
        # take the column 
        name_column = output_df[column]
        # rename the columns 
        column_name = f'{column}_{folder_name}'
        monthly_mean[column_name] = name_column
        monthly_mean.columns = [col[-3:] for col in monthly_mean.columns]


monthly_mean = monthly_mean[elevation_list]

if elevation_list == monthly_mean.columns.tolist():
    print("default land cover. monthly data: same")
else:
    print("not the same")



monthly_mean.columns = elevation.loc['band_data']
# add month column
monthly_mean['month'] = monthly_mean.index.values + 1
monthly_mean['land_cover'] = landcover
print(monthly_mean['land_cover'][1])

# monthly_mean.to_csv(folder_path + '/long_term_mean_monthly_Qstl_elevation_landcover4.csv', index = False)
monthly_mean.to_csv(f'{folder_path}/long_term_mean_monthly_Qstl_elevation_{landcover}.csv', index=False)




# monthly_mean











%%time

# ----- LANGTANG -------

# Path to the directory containing your folders
# directory_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/1landcover/mustang_climate_cut'
# directory_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2landcover/mustang_climate_cut'
# directory_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/3landcover/mustang_climate_cut'
directory_path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/4landcover/langtang_climate_cut'

mean_annual_sum =[]

mean_annual_10 = []
mean_annual_20 = []
mean_annual_25 = []
mean_annual_30 = []
mean_annual_40 = []
mean_annual_50 = []
mean_annual_60 = []
mean_annual_70 = []
mean_annual_75 = []
mean_annual_80 = []
mean_annual_90 = []
mean_annual_100 = []


# Iterate over each folder
for folder_name in os.listdir(directory_path):
    folder_path = os.path.join(directory_path, folder_name)

    if folder_name == '.DS_Store':
        continue
    if folder_name.startswith('.'):
        continue
    # skip all csvs
    if folder_name.endswith('.csv'):
        continue
        
    # Check if it's a directory and its name starts with 'cellnr'
    if os.path.isdir(folder_path): #and folder_name.startswith('cellnr'):

        # Locate the 'sediment.out' file within the folder
        sediment_out_path = os.path.join(folder_path, 'Sediment.out')
        
        # Read the contents of the file into a pandas DataFrame
        df = pd.read_csv(sediment_out_path, delimiter=',')  # Adjust delimiter if needed
        # mean:
        mean_annual_sum_value = functions.annual_sum_mean(df)
        # percentiles:
        mean_annual_10_value = functions.annual_sum_percentile(df, 10)
        mean_annual_20_value = functions.annual_sum_percentile(df, 20)
        mean_annual_25_value = functions.annual_sum_percentile(df, 25)
        mean_annual_30_value = functions.annual_sum_percentile(df, 30)
        mean_annual_40_value = functions.annual_sum_percentile(df, 40)
        mean_annual_50_value = functions.annual_sum_percentile(df, 50)
        mean_annual_60_value = functions.annual_sum_percentile(df, 60)
        mean_annual_70_value = functions.annual_sum_percentile(df, 70)
        mean_annual_75_value = functions.annual_sum_percentile(df, 75)
        mean_annual_80_value = functions.annual_sum_percentile(df, 80)
        mean_annual_90_value = functions.annual_sum_percentile(df, 90)
        mean_annual_100_value =  functions.annual_sum_percentile(df, 100)

       # # Save the DataFrame into the results table
        mean_annual_sum.append((folder_name.replace('cellnr', ''), mean_annual_sum_value))

        mean_annual_10.append((folder_name.replace('cellnr', ''), mean_annual_10_value ))
        mean_annual_20.append((folder_name.replace('cellnr', ''), mean_annual_20_value ))
        mean_annual_25.append((folder_name.replace('cellnr', ''), mean_annual_25_value ))
        mean_annual_30.append((folder_name.replace('cellnr', ''), mean_annual_30_value ))
        mean_annual_40.append((folder_name.replace('cellnr', ''), mean_annual_40_value ))
        mean_annual_50.append((folder_name.replace('cellnr', ''), mean_annual_50_value ))
        mean_annual_60.append((folder_name.replace('cellnr', ''), mean_annual_60_value ))
        mean_annual_70.append((folder_name.replace('cellnr', ''), mean_annual_70_value ))
        mean_annual_75.append((folder_name.replace('cellnr', ''), mean_annual_75_value ))
        mean_annual_80.append((folder_name.replace('cellnr', ''), mean_annual_80_value ))
        mean_annual_90.append((folder_name.replace('cellnr', ''), mean_annual_90_value ))
        mean_annual_100.append((folder_name.replace('cellnr', ''),mean_annual_100_value))



# make table 
mean_annual_sum_df = pd.DataFrame(mean_annual_sum, columns=['cellnr', 'annual_mean_Qstl_mm']).set_index('cellnr')
mean_annual_10_df  = pd.DataFrame(mean_annual_10, columns=['cellnr', 'annual_10percent_Qstl_mm']).set_index('cellnr')
mean_annual_20_df  = pd.DataFrame(mean_annual_20, columns=['cellnr', 'annual_20percent_Qstl_mm']).set_index('cellnr')
mean_annual_25_df  = pd.DataFrame(mean_annual_25, columns=['cellnr', 'annual_25percent_Qstl_mm']).set_index('cellnr')
mean_annual_30_df  = pd.DataFrame(mean_annual_30, columns=['cellnr', 'annual_30percent_Qstl_mm']).set_index('cellnr')
mean_annual_40_df  = pd.DataFrame(mean_annual_40, columns=['cellnr', 'annual_40percent_Qstl_mm']).set_index('cellnr')
mean_annual_50_df  = pd.DataFrame(mean_annual_50, columns=['cellnr', 'annual_50percent_Qstl_mm']).set_index('cellnr')
mean_annual_60_df  = pd.DataFrame(mean_annual_60, columns=['cellnr', 'annual_60percent_Qstl_mm']).set_index('cellnr')
mean_annual_70_df  = pd.DataFrame(mean_annual_70, columns=['cellnr', 'annual_70percent_Qstl_mm']).set_index('cellnr')
mean_annual_75_df  = pd.DataFrame(mean_annual_75, columns=['cellnr', 'annual_75percent_Qstl_mm']).set_index('cellnr')
mean_annual_80_df  = pd.DataFrame(mean_annual_80, columns=['cellnr', 'annual_80percent_Qstl_mm']).set_index('cellnr')
mean_annual_90_df  = pd.DataFrame(mean_annual_90, columns=['cellnr', 'annual_90percent_Qstl_mm']).set_index('cellnr') 
mean_annual_100_df = pd.DataFrame(mean_annual_100, columns=['cellnr', 'annual_100percent_Qstl_mm']).set_index('cellnr')


# merge together
merged_df = pd.concat([mean_annual_sum_df, mean_annual_10_df, mean_annual_20_df,
                       mean_annual_25_df, mean_annual_30_df, mean_annual_40_df, mean_annual_50_df,
                       mean_annual_60_df, mean_annual_70_df, mean_annual_75_df, mean_annual_80_df, 
                       mean_annual_90_df, mean_annual_100_df], axis = 1)


# merged_df.to_csv(directory_path + '/annual_mean_percentiles_for_sediment_input.csv', index = True)


# convert to m3
for column in merged_df.columns:
    # for the columns with _mm in it
    if '_mm' in column:
        # Replace '_mm' with '_m3' and create a new column
        new_column_name = column.replace('_mm', '_m3')
        # convert to m3: 1) [sediments mm to m] 2) [sediments [m] * area [m2]
        merged_df[new_column_name] = (merged_df[column] / 1000) * 4.83 * (10 ** 6)


# calculate the volume of m3 per day 

for column in merged_df.columns:
    if '_m3' in column:
        merged_df[column + '_day'] = merged_df[column] /365


# add coordinates and save the output 

# csv with coordinates and geopotential (z) 

coordinates = pd.read_csv('/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_with_labels_langtang.csv').set_index('cellnr2')
# coordinates = pd.read_csv('/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_with_labels_bagrot.csv').set_index('cellnr2')

# coordinates = pd.read_csv('/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_with_labels_mustang.csv').set_index('cellnr2')
with_coords = pd.concat([merged_df, coordinates],  axis=1).reset_index()
# coordinates

# with_coords


# with_coords.to_csv(directory_path + '/annual_mean_percentiles_for_sediment_input.csv', index = True)


coordinates



