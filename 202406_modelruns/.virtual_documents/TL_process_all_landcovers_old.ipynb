import pandas as pd 
import xarray as xr
import matplotlib.pyplot as plt 
import numpy as np
import os
import seaborn as sns

# import xycmap

import functions















# timestep workaround
column = 'Qstl'
landcover_idx = 4
location = 'langtang'

folder_path = f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/TL_data/{landcover_idx}landcover/langtang_climate_cut'

# read one file to get the time-step
df = functions.calculate_monthly_sediment_yield_all(pd.read_csv(folder_path + '/12a/Sediment.out'), column)
df = df[['month', 'year']]

# elevation langtang
elevation = pd.read_csv('/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_and_elevation_with_labels_langtang.csv')[['cellnr2','band_data']] 
elevation = elevation.transpose()

elevation_list = elevation.loc['cellnr2'].tolist()


output_folder = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/TL_output'


%%time

print(column)
result_df = pd.DataFrame()

# Iterate over the files in the folders
for folder_name in os.listdir(folder_path):
    # skip dsstore thing
    if folder_name == '.DS_Store':
        continue
    # skip all csvs
    if folder_name.endswith('.csv'):
        continue
    file_path = os.path.join(folder_path, folder_name, 'Sediment.out')
    if os.path.isfile(file_path):
        sediments = pd.read_csv(file_path)
        # calculate mean monthly value for given column 
        output_df = functions.calculate_monthly_sediment_yield_all(sediments, column)
        # take the column 
        name_column = output_df[column]
        # rename the columns 
        column_name = f'{column}_{folder_name}'
        result_df[column_name] = name_column
        result_df.columns = [col[-3:] for col in result_df.columns]

# result_df2 = result_df.transpose()

result_df = result_df
result_df = result_df[elevation_list]

if elevation_list == result_df.columns.tolist():
    print("default land cover. monthly data: same")
else:
    print("not the same")


# rename columns according the the elevation and merge with timestep 
result_df.columns = elevation.loc['band_data']
result_df = pd.concat([df, result_df],axis=1)
result_df['land_cover'] = f'landcover_{landcover_idx}'
print(result_df.land_cover[1])


result_df.to_csv(output_folder + f'/{location}_monthly_sum_elevation_{column}_landcover{landcover_idx}.csv', index = False)

# create a dataframe with timestep and attach it to the monthly data dataframe

monthly_data = result_df


# result_df





column = 'Qstl'
landcover_idx = 4
location = 'langtang'

folder_path = f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/TL_data/{landcover_idx}landcover/langtang_climate_cut'



%%time

print(column)
monthly_mean = pd.DataFrame()


# Iterate over the files in the folders
for folder_name in os.listdir(folder_path):
    # skip dsstore thing
    if folder_name == '.DS_Store':
        continue
    # skip all csvs
    if folder_name.endswith('.csv'):
        continue
    file_path = os.path.join(folder_path, folder_name, 'Sediment.out')
    if os.path.isfile(file_path):
        
        # calculate mean monthly value for given column 
        output_df = functions.calculate_monthly_sediment_yield(pd.read_csv(file_path))
        # take the column 
        name_column = output_df[column]
        # rename the columns 
        column_name = f'{column}_{folder_name}'
        monthly_mean[column_name] = name_column
        monthly_mean.columns = [col[-3:] for col in monthly_mean.columns]


monthly_mean = monthly_mean[elevation_list]

if elevation_list == monthly_mean.columns.tolist():
    print("default land cover. monthly data: same")
else:
    print("not the same")



monthly_mean.columns = elevation.loc['band_data']
# add month column
monthly_mean['month'] = monthly_mean.index.values + 1
monthly_mean['land_cover'] = f'landcover_{landcover_idx}'
print(monthly_mean['land_cover'][1])
monthly_mean.to_csv(output_folder + f'/{location}_long_term_mean_monthly_{column}_elevation_landcover{landcover_idx}.csv', index = False)




# monthly_mean





# timestep workaround

column = 'Qstl'
landcover_idx = 4
location = 'mustang'

folder_path = f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/TL_data/{landcover_idx}landcover/{location}_climate_cut'

# read one file to get the time-step
df = functions.calculate_monthly_sediment_yield_all(pd.read_csv(folder_path + '/13a/Sediment.out'), column)
df = df[['month', 'year']]

# elevation langtang
elevation = pd.read_csv('/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_and_elevation_with_labels_mustang.csv')[['cellnr2','band_data']] 
elevation = elevation.transpose()

elevation_list = elevation.loc['cellnr2'].tolist()









%%time


print(column)
result_df = pd.DataFrame()

# Iterate over the files in the folders
for folder_name in os.listdir(folder_path):
    # skip dsstore thing
    if folder_name == '.DS_Store':
        continue
    # skip all csvs
    if folder_name.endswith('.csv'):
        continue
    file_path = os.path.join(folder_path, folder_name, 'Sediment.out')
    if os.path.isfile(file_path):
        sediments = pd.read_csv(file_path)
        # calculate mean monthly value for given column 
        output_df = functions.calculate_monthly_sediment_yield_all(sediments, column)
        # take the column 
        name_column = output_df[column]
        # rename the columns 
        column_name = f'{column}_{folder_name}'
        result_df[column_name] = name_column
        result_df.columns = [col[-3:] for col in result_df.columns]

# result_df2 = result_df.transpose()

result_df = result_df
result_df = result_df[elevation_list]

if elevation_list == result_df.columns.tolist():
    print("default land cover. monthly data: same")
else:
    print("not the same")


# rename columns according the the elevation and merge with timestep 
result_df.columns = elevation.loc['band_data']
result_df = pd.concat([df, result_df],axis=1)
result_df['land_cover'] = f'landcover_{landcover_idx}'
print(result_df.land_cover[1])

result_df.to_csv(output_folder + f'/{location}_monthly_sum_elevation_{column}_landcover{landcover_idx}.csv', index = False)

# create a dataframe with timestep and attach it to the monthly data dataframe











column = 'Qstl'
landcover_idx = 4
location = 'mustang'

folder_path = f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/TL_data/{landcover_idx}landcover/{location}_climate_cut'



%%time


print(column)
monthly_mean = pd.DataFrame()


# Iterate over the files in the folders
for folder_name in os.listdir(folder_path):
    # skip dsstore thing
    if folder_name == '.DS_Store':
        continue
    # skip all csvs
    if folder_name.endswith('.csv'):
        continue
    file_path = os.path.join(folder_path, folder_name, 'Sediment.out')
    if os.path.isfile(file_path):
        
        # calculate mean monthly value for given column 
        output_df = functions.calculate_monthly_sediment_yield(pd.read_csv(file_path))
        # take the column 
        name_column = output_df[column]
        # rename the columns 
        column_name = f'{column}_{folder_name}'
        monthly_mean[column_name] = name_column
        monthly_mean.columns = [col[-3:] for col in monthly_mean.columns]


monthly_mean = monthly_mean[elevation_list]

if elevation_list == monthly_mean.columns.tolist():
    print("default land cover. monthly data: same")
else:
    print("not the same")



monthly_mean.columns = elevation.loc['band_data']
# add month column
monthly_mean['month'] = monthly_mean.index.values + 1
monthly_mean['land_cover'] = f'landcover_{landcover_idx}'
print(monthly_mean['land_cover'][1])

monthly_mean.to_csv(output_folder + f'/{location}_long_term_mean_monthly_{column}_elevation_landcover{landcover_idx}.csv', index = False)







%%time

# ----- LANGTANG -------

column = 'Qstl'
landcover_idx = 4
location = 'mustang'

directory_path = f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/TL_data/{landcover_idx}landcover/{location}_climate_cut'

mean_annual_sum =[]

mean_annual_10 = []
mean_annual_20 = []
mean_annual_25 = []
mean_annual_30 = []
mean_annual_40 = []
mean_annual_50 = []
mean_annual_60 = []
mean_annual_70 = []
mean_annual_75 = []
mean_annual_80 = []
mean_annual_90 = []
mean_annual_100 = []


# Iterate over each folder
for folder_name in os.listdir(directory_path):
    folder_path = os.path.join(directory_path, folder_name)

    if folder_name == '.DS_Store':
        continue
    if folder_name.startswith('.'):
        continue
    # skip all csvs
    if folder_name.endswith('.csv'):
        continue
        
    # Check if it's a directory and its name starts with 'cellnr'
    if os.path.isdir(folder_path): #and folder_name.startswith('cellnr'):

        # Locate the 'sediment.out' file within the folder
        sediment_out_path = os.path.join(folder_path, 'Sediment.out')
        
        # Read the contents of the file into a pandas DataFrame
        df = pd.read_csv(sediment_out_path, delimiter=',')  # Adjust delimiter if needed
        # mean:
        mean_annual_sum_value = functions.annual_sum_mean(df)
        # percentiles:
        mean_annual_10_value = functions.annual_sum_percentile(df, 10)
        mean_annual_20_value = functions.annual_sum_percentile(df, 20)
        mean_annual_25_value = functions.annual_sum_percentile(df, 25)
        mean_annual_30_value = functions.annual_sum_percentile(df, 30)
        mean_annual_40_value = functions.annual_sum_percentile(df, 40)
        mean_annual_50_value = functions.annual_sum_percentile(df, 50)
        mean_annual_60_value = functions.annual_sum_percentile(df, 60)
        mean_annual_70_value = functions.annual_sum_percentile(df, 70)
        mean_annual_75_value = functions.annual_sum_percentile(df, 75)
        mean_annual_80_value = functions.annual_sum_percentile(df, 80)
        mean_annual_90_value = functions.annual_sum_percentile(df, 90)
        mean_annual_100_value =  functions.annual_sum_percentile(df, 100)

       # # Save the DataFrame into the results table
        mean_annual_sum.append((folder_name.replace('cellnr', ''), mean_annual_sum_value))

        mean_annual_10.append((folder_name.replace('cellnr', ''), mean_annual_10_value ))
        mean_annual_20.append((folder_name.replace('cellnr', ''), mean_annual_20_value ))
        mean_annual_25.append((folder_name.replace('cellnr', ''), mean_annual_25_value ))
        mean_annual_30.append((folder_name.replace('cellnr', ''), mean_annual_30_value ))
        mean_annual_40.append((folder_name.replace('cellnr', ''), mean_annual_40_value ))
        mean_annual_50.append((folder_name.replace('cellnr', ''), mean_annual_50_value ))
        mean_annual_60.append((folder_name.replace('cellnr', ''), mean_annual_60_value ))
        mean_annual_70.append((folder_name.replace('cellnr', ''), mean_annual_70_value ))
        mean_annual_75.append((folder_name.replace('cellnr', ''), mean_annual_75_value ))
        mean_annual_80.append((folder_name.replace('cellnr', ''), mean_annual_80_value ))
        mean_annual_90.append((folder_name.replace('cellnr', ''), mean_annual_90_value ))
        mean_annual_100.append((folder_name.replace('cellnr', ''),mean_annual_100_value))



# make table 
mean_annual_sum_df = pd.DataFrame(mean_annual_sum, columns=['cellnr', 'annual_mean_Qstl_mm']).set_index('cellnr')
mean_annual_10_df  = pd.DataFrame(mean_annual_10, columns=['cellnr', 'annual_10percent_Qstl_mm']).set_index('cellnr')
mean_annual_20_df  = pd.DataFrame(mean_annual_20, columns=['cellnr', 'annual_20percent_Qstl_mm']).set_index('cellnr')
mean_annual_25_df  = pd.DataFrame(mean_annual_25, columns=['cellnr', 'annual_25percent_Qstl_mm']).set_index('cellnr')
mean_annual_30_df  = pd.DataFrame(mean_annual_30, columns=['cellnr', 'annual_30percent_Qstl_mm']).set_index('cellnr')
mean_annual_40_df  = pd.DataFrame(mean_annual_40, columns=['cellnr', 'annual_40percent_Qstl_mm']).set_index('cellnr')
mean_annual_50_df  = pd.DataFrame(mean_annual_50, columns=['cellnr', 'annual_50percent_Qstl_mm']).set_index('cellnr')
mean_annual_60_df  = pd.DataFrame(mean_annual_60, columns=['cellnr', 'annual_60percent_Qstl_mm']).set_index('cellnr')
mean_annual_70_df  = pd.DataFrame(mean_annual_70, columns=['cellnr', 'annual_70percent_Qstl_mm']).set_index('cellnr')
mean_annual_75_df  = pd.DataFrame(mean_annual_75, columns=['cellnr', 'annual_75percent_Qstl_mm']).set_index('cellnr')
mean_annual_80_df  = pd.DataFrame(mean_annual_80, columns=['cellnr', 'annual_80percent_Qstl_mm']).set_index('cellnr')
mean_annual_90_df  = pd.DataFrame(mean_annual_90, columns=['cellnr', 'annual_90percent_Qstl_mm']).set_index('cellnr') 
mean_annual_100_df = pd.DataFrame(mean_annual_100, columns=['cellnr', 'annual_100percent_Qstl_mm']).set_index('cellnr')


# merge together
merged_df = pd.concat([mean_annual_sum_df, mean_annual_10_df, mean_annual_20_df,
                       mean_annual_25_df, mean_annual_30_df, mean_annual_40_df, mean_annual_50_df,
                       mean_annual_60_df, mean_annual_70_df, mean_annual_75_df, mean_annual_80_df, 
                       mean_annual_90_df, mean_annual_100_df], axis = 1)

# monthly_mean.to_csv(output_folder + f'/{location}_long_term_mean_monthly_{column}_elevation_landcover{landcover_idx}.csv', index = False)

# merged_df.to_csv(output_folder + f'/{location}_annual_mean_percentiles_for_sediment_input_landcover{landcover_idx}.csv', index = True)


# convert to m3
for column in merged_df.columns:
    # for the columns with _mm in it
    if '_mm' in column:
        # Replace '_mm' with '_m3' and create a new column
        new_column_name = column.replace('_mm', '_m3')
        # convert to m3: 1) [sediments mm to m] 2) [sediments [m] * area [m2]
        merged_df[new_column_name] = (merged_df[column] / 1000) * 4.83 * (10 ** 6)


# calculate the volume of m3 per day 

for column in merged_df.columns:
    if '_m3' in column:
        merged_df[column + '_day'] = merged_df[column] /365


# add coordinates and save the output 

# csv with coordinates and geopotential (z) 

coordinates = pd.read_csv(f'/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_with_labels_{location}.csv').set_index('cellnr2')
with_coords = pd.concat([merged_df, coordinates],  axis=1).reset_index()
# coordinates

with_coords.to_csv(output_folder + f'/{location}_annual_mean_percentiles_for_sediment_input_landcover{landcover_idx}.csv', index = True)











# landcover_indices = [1, 2, 3, 4]

# for landcover_idx in landcover_indices:
#     folder_path = f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/TL_data/{landcover_idx}landcover/{location}_climate_cut'
    
#     print(f"Processing for landcover index: {landcover_idx}")
#     result_df = pd.DataFrame()

#     # Iterate over the files in the folders
#     for folder_name in os.listdir(folder_path):
#         # skip dsstore thing
#         if folder_name == '.DS_Store':
#             continue
#         # skip all csvs
#         if folder_name.endswith('.csv'):
#             continue
#         file_path = os.path.join(folder_path, folder_name, 'Sediment.out')
#         if os.path.isfile(file_path):
#             sediments = pd.read_csv(file_path)
#             # calculate mean monthly value for given column 
#             output_df = functions.calculate_monthly_sediment_yield_all(sediments, column)
#             # take the column 
#             name_column = output_df[column]
#             # rename the columns 
#             column_name = f'{column}_{folder_name}'
#             result_df[column_name] = name_column
#             result_df.columns = [col[-3:] for col in result_df.columns]

#     # Reorder and rename columns as needed
#     result_df = result_df[elevation_list]

#     if elevation_list == result_df.columns.tolist():
#         print("default land cover. monthly data: same")
#     else:
#         print("not the same")

#     # Rename columns according to the elevation and merge with timestep
#     result_df.columns = elevation.loc['band_data']
#     result_df = pd.concat([df, result_df], axis=1)
#     result_df['land_cover'] = f'landcover_{landcover_idx}'

#     # Save result to CSV
#     result_df.to_csv(output_folder + f'/{location}_monthly_sum_elevation_{column}_landcover{landcover_idx}.csv', index=False)

