# MARCH 2025 - calculate floodd and potential DFs for mustang to make a bubble plot 


# Filter the DataFrame for the specified date range


start_date = "1990-08-31"
end_date = "2021-06-30"


def filter_by_date(df, start_date = start_date, end_date = end_date, date_column='D'):
    """
    Filters a DataFrame to include only rows where the date_column is within the given range.

    Parameters:
        df (pd.DataFrame): The input DataFrame.
        start_date (str or pd.Timestamp): The start date (inclusive).
        end_date (str or pd.Timestamp): The end date (inclusive).
        date_column (str): The column containing date values (default is 'D').

    Returns:
        pd.DataFrame: The filtered DataFrame.
    """
    df[date_column] = pd.to_datetime(df[date_column])  # Convert to datetime
    return df[(df[date_column] >= start_date) & (df[date_column] <= end_date)]



'''

def prepare_dfcount(dfcount):
    dfcount['D'] = pd.to_datetime(dfcount['D'])
    
    dfcount = dfcount.drop('D', axis=1)
    dfcount = dfcount.rename(columns={'D_year': 'year', 'D_month': 'month'})
    
    # Melt the dataframe
    melted = pd.melt(dfcount, id_vars=['year', 'month'], var_name='elevation', value_name='dfs_count')
    
    # Process elevation column
    melted['elevation'] = melted['elevation'].str.split('.').str[0].astype(float)

df[['base', 'suffix']] = df['elevation'].astype(str).str.extract(r'(\d+)(?:\.\d+)?(?:\.(\d+))?')
df['base'] = df['base'].astype(int)
df['suffix'] = df['suffix'].fillna(0).astype(int)
df['elevation'] = df['base'] + df['suffix']

    
    melted['elevation_bin'] = melted.apply(functions.bin_elevation500, axis=1)
    
    # Create unique id for elevation and month for merging
    melted['elevation'] = melted['elevation'].astype(int)
    melted['id'] = melted.index.astype(str) + "_" + melted['elevation'].astype(str) + "_" + melted['year'].astype(str) + "_" + melted['month'].astype(str)
    # melted['id'] = melted['elevation'].astype(str) + "_" + melted['year'].astype(str) + "_" + melted['month'].astype(str)
    
    return melted
'''

def prepare_dfcount(dfcount):
    # dfcount['D'] = pd.to_datetime(dfcount['D'])
    
    # dfcount = dfcount.drop('D', axis=1)
    dfcount = dfcount.drop('land_cover', axis = 1)
    
    # dfcount = dfcount.rename(columns={'D_year': 'year', 'D_month': 'month'})
    
    # Melt the dataframe
    melted = pd.melt(dfcount, id_vars=['year', 'month'], var_name='elevation', value_name='dfs_volume')
    
    # Process elevation column
    melted[['base', 'suffix']] = melted['elevation'].astype(str).str.extract(r'(\d+)(?:\.\d+)?(?:\.(\d+))?')
    melted['base'] = melted['base'].astype(int)
    melted['suffix'] = melted['suffix'].fillna(0).astype(int)
    melted['elevation'] = melted['base'] + melted['suffix']*10
    melted['elevation'] = melted['elevation'].astype(float)


    
    melted['elevation_bin'] = melted.apply(functions.bin_elevation500, axis=1)
    
    # Create unique id for elevation and month for merging
    melted['elevation'] = melted['elevation'].astype(int)
    # melted['id'] = melted.index.astype(str) + "_" + melted['elevation'].astype(str) + "_" + melted['year'].astype(str) + "_" + melted['month'].astype(str)
    melted['id'] = melted['elevation'].astype(str) + "_" + melted['year'].astype(str) + "_" + melted['month'].astype(str)
    
    return melted



def prepare_dfvol_limitation(df_vol):
    
    df_vol = df_vol.drop('folder', axis=1)
    melted = pd.melt(df_vol, id_vars=['year', 'month'], var_name='elevation', value_name='dfs_volume')
    melted[['base', 'suffix']] = melted['elevation'].astype(str).str.extract(r'(\d+)(?:\.\d+)?(?:\.(\d+))?')
    melted['base'] = melted['base'].astype(int)
    melted['suffix'] = melted['suffix'].fillna(0).astype(int)
    melted['elevation'] = melted['base'] + melted['suffix']*10
    melted['elevation'] = melted['elevation'].astype(float)
    melted['elevation_bin'] = melted.apply(functions.bin_elevation500, axis=1)
    # Create unique id for elevation and month for merging
    melted['elevation'] = melted['elevation'].astype(int)
    melted['id'] = melted['elevation'].astype(str) + "_" + melted['year'].astype(str) + "_" + melted['month'].astype(str)
    
    return melted






# def merge_landcover_dfs(dfs, dfspot, merge_on, dfspot_column):
#     """
#     Merges a list of dataframes on specified columns and adds a column from a 'dfspot' dataframe.
    
#     Parameters:
#         dfs (list of pd.DataFrame): List of dataframes to merge sequentially.
#         dfspot (pd.DataFrame): A dataframe containing a column to add after the merges.
#         merge_on (list of str): Columns to use as the merge keys.
#         dfspot_column (str): The name of the column in `dfspot` to add after merging.
        
#     Returns:
#         pd.DataFrame: The merged dataframe with the additional column from `dfspot`.
#     """
    
#     # Start with the first dataframe in `dfs` and automatically get the count column
#     count_column = [col for col in dfs[0].columns if col.startswith('dfs_volume')][0]
#     merged_df = dfs[0][merge_on + [count_column]]
    
#     # Iterate over remaining dataframes and merge each sequentially
#     for df in dfs[1:]:
#         count_column = [col for col in df.columns if col.startswith('dfs_volume')][0]
#         merged_df = pd.merge(merged_df, df[merge_on + [count_column]], on=merge_on)
    
#     # Add the `dfspot_column` from `dfspot` dataframe to the merged dataframe
#     merged_df['dfspot_volume'] = dfspot[dfspot_column]
    
#     return merged_df



def merge_landcover_dfs(dfs, merge_on):
    """
    Merges a list of dataframes on specified columns and adds a column from a 'dfspot' dataframe.
    
    Parameters:
        dfs (list of pd.DataFrame): List of dataframes to merge sequentially.
        dfspot (pd.DataFrame): A dataframe containing a column to add after the merges.
        merge_on (list of str): Columns to use as the merge keys.
        dfspot_column (str): The name of the column in `dfspot` to add after merging.
        
    Returns:
        pd.DataFrame: The merged dataframe with the additional column from `dfspot`.
    """
    
    # Start with the first dataframe in `dfs` and automatically get the count column
    count_column = [col for col in dfs[0].columns if col.startswith('dfs_volume')][0]
    merged_df = dfs[0][merge_on + [count_column]]
    
    # Iterate over remaining dataframes and merge each sequentially
    for df in dfs[1:]:
        count_column = [col for col in df.columns if col.startswith('dfs_volume')][0]
        merged_df = pd.merge(merged_df, df[merge_on + [count_column]], on=merge_on)
    
    # Add the `dfspot_column` from `dfspot` dataframe to the merged dataframe
    # merged_df['dfspot_volume'] = dfspot[dfspot_column]
    
    return merged_df



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import glob

import functions



























# # Base directory where all output_Xpercent folders are located
# base_directory = "/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025Jan_output/SL_daily/"

# # Use glob to find all relevant files in output_XXpercent folders
# file_pattern = f"{base_directory}/output_*/mustang_monthly_dfs_count_*_landcover{landcover_idx}.csv"
# files = glob.glob(file_pattern)
# print(files)




import glob
import pandas as pd
import re

location = 'mustang'
landcover_idx = 5
method = 'once'


# Base directory where all output_Xpercent folders are located
base_directory = f"/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025May_output/SL_{method}"

# Use glob to find all relevant files in output_XXpercent folders
file_pattern = f"{base_directory}/output_*/{location}_monthly_sum_elevation_dfs_*_{landcover_idx}landcover_mm.csv"
files = glob.glob(file_pattern)

# print(file_pattern)
# print(files)


dfs = []

# Loop through the files and process them
for file in files:
    # Extract the percentile from the folder name
    percentile = re.search(r'output_(\d+percent)', file).group(1)
    
    # Extract the landcover number from the file name
    landcover_number = re.search(r'(\d+)landcover', file).group(1)
    print(landcover_number)
    print(file)
    # Read the file into a DataFrame
    df = pd.read_csv(file).fillna(0)


    # df = filter_by_date(df)

    # Apply your processing function
    processed_df = prepare_dfvol_limitation(df)
    
    # Rename the 'dfs_count' column to include percentile and landcover number
    processed_df = processed_df.rename(columns={'dfs_volume': f'dfs_volume_{percentile}'})


    
    # Append to the list
    dfs.append(processed_df)




merge_on = ['year', 'month', 'elevation', 'elevation_bin', 'id']
# merge_on = ['id']
dfspot_column = 'dfs_volume'

if landcover_idx == 1:
    dfspot = dfspot1
if landcover_idx == 2:
    dfspot = dfspot2
if landcover_idx == 3:
    dfspot = dfspot3
if landcover_idx == 4:
    dfspot = dfspot4
if landcover_idx == 5:
    dfspot = dfspot5


dfmerged = merge_landcover_dfs(dfs, merge_on)
# dffloods = calculate_floods(dfmerged)


outpath = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025May_output/df_vs_floods/dfs_volume/'
dfmerged.to_csv(outpath + f'{location}_df_volumes_{method}_landcover{landcover_idx}.csv')










































# test = pd.read_csv('/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025May_output/SL_daily/output_20percent/langtang_monthly_sum_elevation_dfs_20percent_1landcover_mm.csv')

test = pd.read_csv('/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025May_output/SL_once/output_30percent/langtang_monthly_sum_elevation_dfs_30percent_1landcover_mm.csv')





test = test.drop('folder', axis=1)
melted = pd.melt(test, id_vars=['year', 'month'], var_name='elevation', value_name='dfs_volume')

melted[['base', 'suffix']] = melted['elevation'].astype(str).str.extract(r'(\d+)(?:\.\d+)?(?:\.(\d+))?')
melted['base'] = melted['base'].astype(int)
melted['suffix'] = melted['suffix'].fillna(0).astype(int)
melted['elevation'] = melted['base'] + melted['suffix']*10
melted['elevation'] = melted['elevation'].astype(float)


melted['elevation_bin'] = melted.apply(functions.bin_elevation500, axis=1)
    
# Create unique id for elevation and month for merging
melted['elevation'] = melted['elevation'].astype(int)
melted['id'] = melted['elevation'].astype(str) + "_" + melted['year'].astype(str) + "_" + melted['month'].astype(str)
    




