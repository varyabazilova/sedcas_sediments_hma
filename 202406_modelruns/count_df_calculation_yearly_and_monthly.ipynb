{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6843ee3a-e51c-4702-ad3c-cec9d8c7911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "\n",
    "\n",
    "import functions\n",
    "\n",
    "\n",
    "# the data is stored on the external ssd \n",
    "# the output should go to the local folder \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6de4632-d651-4ba7-8231-400140efb0af",
   "metadata": {},
   "source": [
    "# per year\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c73fab8-af2a-4f6c-a47e-3afd6dc5cd53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a18af281-f636-4184-9edb-f98eb4af9314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path - data that sits on the SSD drive - outout of model runs \n",
    "# output_path - folder to save all the things, related to the scenario \n",
    "# dfspot - potential dfs = TL situation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3658e47e-cf62-4e6e-9410-07244fa70853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default land cover. monthly data: same\n",
      "Processed 50percent for landcover index 1\n",
      "default land cover. monthly data: same\n",
      "Processed 50percent for landcover index 2\n",
      "default land cover. monthly data: same\n",
      "Processed 50percent for landcover index 3\n",
      "default land cover. monthly data: same\n",
      "Processed 50percent for landcover index 4\n",
      "default land cover. monthly data: same\n",
      "Processed 50percent for landcover index 5\n",
      "default land cover. monthly data: same\n",
      "Processed 60percent for landcover index 1\n",
      "default land cover. monthly data: same\n",
      "Processed 60percent for landcover index 2\n",
      "default land cover. monthly data: same\n",
      "Processed 60percent for landcover index 3\n",
      "default land cover. monthly data: same\n",
      "Processed 60percent for landcover index 4\n",
      "default land cover. monthly data: same\n",
      "Processed 60percent for landcover index 5\n",
      "CPU times: user 2min 29s, sys: 6.73 s, total: 2min 35s\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# List of landcover indices and percentiles\n",
    "landcover_indices = [1, 2, 3, 4, 5]\n",
    "# percentiles = ['20percent', '30percent', '40percent']#, '50percent', '60percent']\n",
    "percentiles = ['50percent', '60percent']\n",
    "location = 'langtang'\n",
    "\n",
    "method = 'once'\n",
    "column = 'dfs'  \n",
    "freq = 'year'  \n",
    "\n",
    "# Load elevation data once, outside the loops\n",
    "elevation = pd.read_csv(f'/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_and_elevation_with_labels_{location}.csv')[['cellnr2', 'band_data']]\n",
    "\n",
    "# Iterate over each percentile\n",
    "for percentile in percentiles:\n",
    "    # Define the output path for the current percentile\n",
    "    output_path = f'/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025Jan_output/SL_{method}/output_{percentile}'\n",
    "    \n",
    "    # Iterate over each landcover index\n",
    "    for landcover_idx in landcover_indices:\n",
    "        # folder_path = f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_{method}/{landcover_idx}landcover_{percentile}/{location}_climate_cut'\n",
    "        folder_path = f'/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_data_{method}/{landcover_idx}landcover_{percentile}/{location}_climate_cut'\n",
    "        # folder_path = f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_{method}/{landcover_idx}landcover_{percentile}/{location}_climate_cut'\n",
    "        result_df = pd.DataFrame()\n",
    "\n",
    "        # Iterate over the files in the folders\n",
    "        for folder_name in os.listdir(folder_path):\n",
    "            # Skip all csvs and hidden files\n",
    "            if folder_name.endswith('.csv') or folder_name.startswith('.'):\n",
    "                continue\n",
    "            \n",
    "            file_path = os.path.join(folder_path, folder_name, 'Sediment.out')\n",
    "            \n",
    "            if os.path.isfile(file_path):\n",
    "                # Read file\n",
    "                output_df = pd.read_csv(file_path)\n",
    "                # Count dfs per given time\n",
    "                output_df = functions.count_dfs_per_time(output_df, column, freq)\n",
    "                \n",
    "                # Take the COUNT column\n",
    "                name_column = output_df['count']\n",
    "                # Rename the columns\n",
    "                column_name = f'{column}_{folder_name}'\n",
    "                result_df[column_name] = name_column\n",
    "                result_df.columns = [col[-3:] for col in result_df.columns]\n",
    "\n",
    "        # Add elevation data to the result_df\n",
    "        annaul_df_count = functions.add_elevation_to_df_count(result_df, elevation, freq)\n",
    "\n",
    "        # Save the resulting DataFrame to a CSV file for the current landcover index and percentile\n",
    "        output_filename = f'{location}_annual_{column}_count{percentile}_landcover{landcover_idx}.csv'\n",
    "        annaul_df_count.to_csv(os.path.join(output_path, output_filename))\n",
    "\n",
    "        print(f\"Processed {percentile} for landcover index {landcover_idx}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3c1b77-f8dc-4c70-ba73-3053613c076e",
   "metadata": {},
   "source": [
    "# month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "107775a4-a5ac-408e-983b-c0c3f150d201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default land cover. monthly data: same\n",
      "Processed 50percent for landcover index 1\n",
      "default land cover. monthly data: same\n",
      "Processed 50percent for landcover index 2\n",
      "default land cover. monthly data: same\n",
      "Processed 50percent for landcover index 3\n",
      "default land cover. monthly data: same\n",
      "Processed 50percent for landcover index 4\n",
      "default land cover. monthly data: same\n",
      "Processed 50percent for landcover index 5\n",
      "default land cover. monthly data: same\n",
      "Processed 60percent for landcover index 1\n",
      "default land cover. monthly data: same\n",
      "Processed 60percent for landcover index 2\n",
      "default land cover. monthly data: same\n",
      "Processed 60percent for landcover index 3\n",
      "default land cover. monthly data: same\n",
      "Processed 60percent for landcover index 4\n",
      "default land cover. monthly data: same\n",
      "Processed 60percent for landcover index 5\n",
      "CPU times: user 8min 47s, sys: 23.8 s, total: 9min 10s\n",
      "Wall time: 9min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# List of landcover indices and percentiles\n",
    "landcover_indices = [1, 2, 3, 4, 5]\n",
    "# percentiles = ['20percent', '30percent', '40percent']#, '50percent', '60percent']\n",
    "percentiles = ['50percent', '60percent']\n",
    "\n",
    "location = 'mustang'\n",
    "\n",
    "method = 'once'\n",
    "column = 'dfs'  \n",
    "freq = 'month'  \n",
    "\n",
    "# Load elevation data once, outside the loops\n",
    "elevation = pd.read_csv(f'/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_and_elevation_with_labels_{location}.csv')[['cellnr2', 'band_data']]\n",
    "\n",
    "# Iterate over each percentile\n",
    "for percentile in percentiles:\n",
    "    # Define the output path for the current percentile\n",
    "    output_path = f'/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025Jan_output/SL_{method}/output_{percentile}'\n",
    "    \n",
    "    # Iterate over each landcover index\n",
    "    for landcover_idx in landcover_indices:\n",
    "        # folder_path = f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_{method}/{landcover_idx}landcover_{percentile}/{location}_climate_cut'\n",
    "        folder_path = f'/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_data_{method}/{landcover_idx}landcover_{percentile}/{location}_climate_cut'\n",
    "        # folder_path = f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_{method}/{landcover_idx}landcover_{percentile}/{location}_climate_cut'\n",
    "\n",
    "        result_df = pd.DataFrame()\n",
    "\n",
    "        # Iterate over the files in the folders\n",
    "        for folder_name in os.listdir(folder_path):\n",
    "            # Skip all csvs and hidden files\n",
    "            if folder_name.endswith('.csv') or folder_name.startswith('.'):\n",
    "                continue\n",
    "            \n",
    "            file_path = os.path.join(folder_path, folder_name, 'Sediment.out')\n",
    "            \n",
    "            if os.path.isfile(file_path):\n",
    "                # Read file\n",
    "                output_df = pd.read_csv(file_path)\n",
    "                # Count dfs per given time\n",
    "                output_df = functions.count_dfs_per_time(output_df, column, freq)\n",
    "                \n",
    "                # Take the COUNT column\n",
    "                name_column = output_df['count']\n",
    "                # Rename the columns\n",
    "                column_name = f'{column}_{folder_name}'\n",
    "                result_df[column_name] = name_column\n",
    "                result_df.columns = [col[-3:] for col in result_df.columns]\n",
    "\n",
    "        # Add elevation data to the result_df\n",
    "        annaul_df_count = functions.add_elevation_to_df_count(result_df, elevation, freq)\n",
    "\n",
    "        # Save the resulting DataFrame to a CSV file for the current landcover index and percentile\n",
    "        output_filename = f'{location}_monthly_{column}_count_{percentile}_landcover{landcover_idx}.csv'\n",
    "        annaul_df_count.to_csv(os.path.join(output_path, output_filename))\n",
    "\n",
    "        print(f\"Processed {percentile} for landcover index {landcover_idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287992db-692f-49c1-aafc-d1a3f72953da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6b2c4f-46fa-4575-9825-281222c237db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dd92a4-53b4-4f59-a971-f904a4fe9cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d73d7-b299-45b5-b36f-50509355917f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "657edd12-348f-42fd-9cd1-ded6a25926df",
   "metadata": {},
   "source": [
    "# TL (dfspot count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336281c5-734e-443d-8485-afda4b61230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# List of landcover indices and percentiles\n",
    "landcover_indices = [1, 2, 3, 4, 5]\n",
    "percentiles = ['40percent']\n",
    "\n",
    "location = 'langtang'\n",
    "\n",
    "method = 'daily'\n",
    "column = 'dfspot'  \n",
    "freq = 'year'  \n",
    "\n",
    "# Load elevation data once, outside the loops\n",
    "elevation = pd.read_csv(f'/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_and_elevation_with_labels_{location}.csv')[['cellnr2', 'band_data']]\n",
    "\n",
    "# Iterate over each percentile\n",
    "for percentile in percentiles:\n",
    "    # Define the output path for the current percentile\n",
    "    output_path = f'/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2024Nov_output/TL/'\n",
    "    \n",
    "    # Iterate over each landcover index\n",
    "    for landcover_idx in landcover_indices:\n",
    "        folder_path = f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_{method}/{landcover_idx}landcover_{percentile}/{location}_climate_cut'\n",
    "        result_df = pd.DataFrame()\n",
    "\n",
    "        # Iterate over the files in the folders\n",
    "        for folder_name in os.listdir(folder_path):\n",
    "            # Skip all csvs and hidden files\n",
    "            if folder_name.endswith('.csv') or folder_name.startswith('.'):\n",
    "                continue\n",
    "            \n",
    "            file_path = os.path.join(folder_path, folder_name, 'Sediment.out')\n",
    "            \n",
    "            if os.path.isfile(file_path):\n",
    "                # Read file\n",
    "                output_df = pd.read_csv(file_path)\n",
    "                # Count dfs per given time\n",
    "                output_df = functions.count_dfs_per_time(output_df, column, freq)\n",
    "                \n",
    "                # Take the COUNT column\n",
    "                name_column = output_df['count']\n",
    "                # Rename the columns\n",
    "                column_name = f'{column}_{folder_name}'\n",
    "                result_df[column_name] = name_column\n",
    "                result_df.columns = [col[-3:] for col in result_df.columns]\n",
    "\n",
    "        # Add elevation data to the result_df\n",
    "        annaul_df_count = functions.add_elevation_to_df_count(result_df, elevation, freq)\n",
    "\n",
    "        # Save the resulting DataFrame to a CSV file for the current landcover index and percentile\n",
    "        output_filename = f'{location}_monthly_{column}_count_{percentile}_landcover{landcover_idx}.csv'\n",
    "        annaul_df_count.to_csv(os.path.join(output_path, output_filename))\n",
    "\n",
    "        print(f\"Processed {percentile} for landcover index {landcover_idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ba51e-d898-45cd-9af5-910653fc311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# List of landcover indices and percentiles\n",
    "landcover_indices = [1, 2, 3, 4]\n",
    "percentiles = ['40percent']\n",
    "\n",
    "location = 'langtang'\n",
    "\n",
    "method = 'daily'\n",
    "column = 'dfspot'  \n",
    "freq = 'month'  \n",
    "\n",
    "# Load elevation data once, outside the loops\n",
    "elevation = pd.read_csv(f'/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_and_elevation_with_labels_{location}.csv')[['cellnr2', 'band_data']]\n",
    "\n",
    "# Iterate over each percentile\n",
    "for percentile in percentiles:\n",
    "    # Define the output path for the current percentile\n",
    "    output_path = f'/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2024Nov_output/TL/'\n",
    "    \n",
    "    # Iterate over each landcover index\n",
    "    for landcover_idx in landcover_indices:\n",
    "        folder_path = f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_{method}/{landcover_idx}landcover_{percentile}/{location}_climate_cut'\n",
    "        result_df = pd.DataFrame()\n",
    "\n",
    "        # Iterate over the files in the folders\n",
    "        for folder_name in os.listdir(folder_path):\n",
    "            # Skip all csvs and hidden files\n",
    "            if folder_name.endswith('.csv') or folder_name.startswith('.'):\n",
    "                continue\n",
    "            \n",
    "            file_path = os.path.join(folder_path, folder_name, 'Sediment.out')\n",
    "            \n",
    "            if os.path.isfile(file_path):\n",
    "                # Read file\n",
    "                output_df = pd.read_csv(file_path)\n",
    "                # Count dfs per given time\n",
    "                output_df = functions.count_dfs_per_time(output_df, column, freq)\n",
    "                \n",
    "                # Take the COUNT column\n",
    "                name_column = output_df['count']\n",
    "                # Rename the columns\n",
    "                column_name = f'{column}_{folder_name}'\n",
    "                result_df[column_name] = name_column\n",
    "                result_df.columns = [col[-3:] for col in result_df.columns]\n",
    "\n",
    "        # Add elevation data to the result_df\n",
    "        annaul_df_count = functions.add_elevation_to_df_count(result_df, elevation, freq)\n",
    "\n",
    "        # Save the resulting DataFrame to a CSV file for the current landcover index and percentile\n",
    "        output_filename = f'{location}_monthly_{column}_count_{percentile}_landcover{landcover_idx}.csv'\n",
    "        annaul_df_count.to_csv(os.path.join(output_path, output_filename))\n",
    "\n",
    "        print(f\"Processed {percentile} for landcover index {landcover_idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b18e5e-fb34-4c6e-9ed9-64c3c7617c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fa6e58-ef98-4e14-bfa2-9749781e64b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c122a515-3086-4d3c-b3b2-574fe7d29ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2f228-9a05-4e7a-94a3-491167fb5bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dbb35d-dc3c-4e0b-bee3-a1f94a69451a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc29d5d-f3f5-4d23-9934-6b14604b0c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc38799-2b5a-491f-a517-184771ffc598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60df880-9454-4ac8-97c5-63367f0067e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd65b450-c93f-4ab6-b2c0-4fbe338e7f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad454207-6f78-46a4-bfc5-cd4bf5e86a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_dfs_per_time(sediments, column, freq):\n",
    "    '''\n",
    "    sediments - sediment output file\n",
    "    column - column of interest (e.g. dfs)\n",
    "    freq - resampling frequency\n",
    "    '''\n",
    "\n",
    "    sediments['D'] = pd.to_datetime(sediments.D)\n",
    "    sediments = sediments.set_index('D')\n",
    "    sediments = sediments[sediments[column] > 0]\n",
    "    sediments['count'] = sediments[column].apply(lambda x: 1 if x != 0 else 0)\n",
    "\n",
    "    \n",
    "    if freq == 'month':\n",
    "        # calculate how many dfs are there per month \n",
    "        sym = sediments.resample('m').sum()\n",
    "        return sym\n",
    "    \n",
    "    elif freq == 'year':\n",
    "        # calculate how many dfs are there per year \n",
    "        sym_year = sediments.resample('Y').sum()\n",
    "        return sym_year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9e9317-bdfc-435c-896f-abba2da3445f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f5e34-ad42-4d89-8c51-a89fb9589c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8576c173-7643-4a2b-87f6-c9a5f3e538a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39908a41-e0e5-4ee9-8278-f999b0fc99d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sedcas] *",
   "language": "python",
   "name": "conda-env-sedcas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
