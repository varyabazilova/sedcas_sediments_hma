{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4c78b1e-b06e-442e-88a5-d4488b1b16d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "# import xycmap\n",
    "\n",
    "import functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733654b2-d081-442d-b5cc-7b970894b337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09322d73-2503-4e5e-9528-4793e88be4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ad26d9-df07-42b3-9cc5-b0e2ffa96c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_folder = f'/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2024Nov_output/TL/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d12668-acb7-48e1-b468-9014d074b8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing landcover index 1 and percentile 30percent\n",
      "default land cover. monthly data: same\n",
      "     month  year         4485.0        3734.0  4880.0  4847.0        3908.0  \\\n",
      "0        9  1989       0.000000  0.000000e+00     0.0     0.0  0.000000e+00   \n",
      "1       10  1989       0.000000  0.000000e+00     0.0     0.0  0.000000e+00   \n",
      "2       11  1989       0.000000  0.000000e+00     0.0     0.0  0.000000e+00   \n",
      "3       12  1989       0.000000  0.000000e+00     0.0     0.0  0.000000e+00   \n",
      "4        1  1990       0.000000  0.000000e+00     0.0     0.0  0.000000e+00   \n",
      "..     ...   ...            ...           ...     ...     ...           ...   \n",
      "392      5  2022       0.000000  0.000000e+00     0.0     0.0  0.000000e+00   \n",
      "393      6  2022  401182.400185  1.239064e+06     0.0     0.0  1.364211e+06   \n",
      "394      7  2022  829515.500660  1.279493e+06     0.0     0.0  1.443771e+06   \n",
      "395      8  2022  485112.433802  9.332687e+05     0.0     0.0  3.907959e+05   \n",
      "396      9  2022       0.000000  4.691458e+04     0.0     0.0  0.000000e+00   \n",
      "\n",
      "           3756.0        4498.0  4933.0  ...  5699.0  5384.0  5217.0  5870.0  \\\n",
      "0    0.000000e+00  0.000000e+00     0.0  ...     0.0     0.0     0.0     0.0   \n",
      "1    0.000000e+00  0.000000e+00     0.0  ...     0.0     0.0     0.0     0.0   \n",
      "2    0.000000e+00  0.000000e+00     0.0  ...     0.0     0.0     0.0     0.0   \n",
      "3    0.000000e+00  0.000000e+00     0.0  ...     0.0     0.0     0.0     0.0   \n",
      "4    0.000000e+00  0.000000e+00     0.0  ...     0.0     0.0     0.0     0.0   \n",
      "..            ...           ...     ...  ...     ...     ...     ...     ...   \n",
      "392  0.000000e+00  0.000000e+00     0.0  ...     0.0     0.0     0.0     0.0   \n",
      "393  1.421702e+06  1.037909e+06     0.0  ...     0.0     0.0     0.0     0.0   \n",
      "394  1.526597e+06  5.800872e+05     0.0  ...     0.0     0.0     0.0     0.0   \n",
      "395  6.902645e+05  0.000000e+00     0.0  ...     0.0     0.0     0.0     0.0   \n",
      "396  0.000000e+00  0.000000e+00     0.0  ...     0.0     0.0     0.0     0.0   \n",
      "\n",
      "     5424.0  5763.0  6335.0  5859.0  5936.0  land_cover  \n",
      "0       0.0     0.0     0.0     0.0     0.0  landcover1  \n",
      "1       0.0     0.0     0.0     0.0     0.0  landcover1  \n",
      "2       0.0     0.0     0.0     0.0     0.0  landcover1  \n",
      "3       0.0     0.0     0.0     0.0     0.0  landcover1  \n",
      "4       0.0     0.0     0.0     0.0     0.0  landcover1  \n",
      "..      ...     ...     ...     ...     ...         ...  \n",
      "392     0.0     0.0     0.0     0.0     0.0  landcover1  \n",
      "393     0.0     0.0     0.0     0.0     0.0  landcover1  \n",
      "394     0.0     0.0     0.0     0.0     0.0  landcover1  \n",
      "395     0.0     0.0     0.0     0.0     0.0  landcover1  \n",
      "396     0.0     0.0     0.0     0.0     0.0  landcover1  \n",
      "\n",
      "[397 rows x 55 columns]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2024Nov_output/SL_once/output_30percent/langtang_monthly_sum_elevation_Q100_landcover1_30percent.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sedcas/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3464\u001b[0m         )\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3466\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sedcas/lib/python3.9/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sedcas/lib/python3.9/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m    236\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sedcas/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2024Nov_output/SL_once/output_30percent/langtang_monthly_sum_elevation_Q100_landcover1_30percent.csv'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define the list of landcover indices and percentiles\n",
    "landcover_indices = [1, 2, 3, 4]\n",
    "# percentiles = ['20percent', '30percent', '40percent']#, '50percent', '60percent']\n",
    "percentiles = ['30percent']\n",
    "method = 'once'  # Define your method here\n",
    "column = 'Q100'  # Set the target column\n",
    "location = 'langtang'\n",
    "\n",
    "folder_langtang = '12a'\n",
    "folder_mustang = '13a'\n",
    "\n",
    "\n",
    "# Load elevation data and define the output path\n",
    "elevation = pd.read_csv(f'/Users/varyabazilova/Desktop/paper2/downscaling_simple/coordinates_and_elevation_with_labels_{location}.csv')[['cellnr2', 'band_data']]\n",
    "elevation = elevation.transpose()\n",
    "elevation_list = elevation.loc['cellnr2'].tolist()  # Adjust if you need a specific list format\n",
    "\n",
    "\n",
    "# Loop over each landcover index\n",
    "for landcover_idx in landcover_indices:\n",
    "\n",
    "    # result_df = pd.DataFrame()\n",
    "    \n",
    "    # Loop over each percentile\n",
    "    for percentile in percentiles:\n",
    "        print(f\"Processing landcover index {landcover_idx} and percentile {percentile}\")\n",
    "\n",
    "        output_folder = f'/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2024Nov_output/SL_{method}/output_{percentile}'\n",
    "        # output_folder = f'/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2024Nov_output/TL'\n",
    "        # Define folder paths for each iteration\n",
    "        # folder_path = f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_{method}/{landcover_idx}landcover_{percentile}/{location}_climate_cut'\n",
    "        folder_path = f'/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_data_{method}/1landcover_{percentile}/{location}_climate_cut'\n",
    "        # timestep workaround \n",
    "        df = functions.calculate_monthly_sediment_yield_all(pd.read_csv(folder_path + f'/{folder_langtang}/Sediment.out'), column)\n",
    "        df = df[['month', 'year']]\n",
    "\n",
    "        \n",
    "        result_df = pd.DataFrame()\n",
    "\n",
    "        # Iterate over files in the folder\n",
    "        for folder_name in os.listdir(folder_path):\n",
    "            # Skip unwanted files\n",
    "            if folder_name.endswith('.csv') or folder_name.startswith('.'):\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(folder_path, folder_name, 'Sediment.out')\n",
    "            if os.path.isfile(file_path):\n",
    "                # Read sediment data and calculate mean monthly value\n",
    "                sediments = pd.read_csv(file_path)\n",
    "                output_df = functions.calculate_monthly_sediment_yield_all(sediments, column)\n",
    "                \n",
    "                # Take the column and rename it\n",
    "                name_column = output_df[column]\n",
    "                column_name = f'{column}_{folder_name}'\n",
    "                result_df[column_name] = name_column\n",
    "                result_df.columns = [col[-3:] for col in result_df.columns]  # Rename columns for each folder\n",
    "\n",
    "\n",
    "        \n",
    "        # # Filter result_df by elevation list\n",
    "        result_df = result_df[elevation_list]\n",
    "\n",
    "        # Check for consistency with elevation list\n",
    "        if elevation_list == result_df.columns.tolist():\n",
    "            print(\"default land cover. monthly data: same\")\n",
    "            \n",
    "            # Rename columns, merge with timestep, and add land cover info\n",
    "            result_df.columns = elevation.loc['band_data']\n",
    "            result_df = pd.concat([df, result_df], axis=1)  # Assuming `df` is defined elsewhere and aligns as expected\n",
    "            result_df['land_cover'] = f'landcover{landcover_idx}'\n",
    "\n",
    "\n",
    "            print(result_df)\n",
    "            \n",
    "            # Define the output file name and save the DataFrame to a CSV file\n",
    "            output_filename = f'{location}_monthly_sum_elevation_{column}_landcover{landcover_idx}_{percentile}.csv'\n",
    "            result_df.to_csv(os.path.join(output_folder, output_filename), index=False)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            print(f\"Saved {output_filename}\")\n",
    "        else: print('its not the same AAAA!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccfe23c-8b83-4713-a327-475293d1b28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a2acfc-2f71-4acf-b59d-48eeaaf4e706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8668ad23-0843-4c6b-a61c-a9bc670daeb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b3771-c587-40ac-8f4d-eff224e72136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d60990-0723-45e6-9518-7060cfc7bc62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3341145a-b4e1-48cb-97f3-d81da42865f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a2212-f7d1-4778-9f75-9bea414b4b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e50fb-2368-4442-ba53-4a54c02481fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bb84b6-9bde-4dac-936e-f5ba41d1e29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb581b7-d98b-424d-9e7f-3646d70e9829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f744e3-deff-4bd5-80a4-3c81a61a252a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e967189-617f-4ab9-858f-3d9267ee470f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf342ea5-cb6b-47f5-bad3-ca68b5a2a274",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.columns = elevation.loc['band_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31519070-6961-4866-b47a-6d893b879e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b459cfd1-5f63-4ff2-9e1a-22fb37da3d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e2bd59-1787-46cd-8f5b-7c264e01da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define the list of landcover indices and percentiles\n",
    "landcover_indices = [1, 2, 3, 4]\n",
    "percentiles = ['20percent', '30percent', '40percent', '50percent', '60percent']\n",
    "location = 'langtang'\n",
    "method = 'daily' \n",
    "\n",
    "# Set the column and other parameters\n",
    "column = 'Q100'\n",
    "\n",
    "df = pd.DataFrame()  # Assuming `df` is initialized as needed\n",
    "\n",
    "# Loop over each landcover index\n",
    "for landcover_idx in landcover_indices:\n",
    "    # Loop over each percentile\n",
    "    for percentile in percentiles:\n",
    "        print(f\"Processing landcover index {landcover_idx} and percentile {percentile}\")\n",
    "        \n",
    "        # Define folder paths\n",
    "        folder_path = f'/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_{method}/{landcover_idx}landcover_{percentile}/{location}_climate_cut'\n",
    "        output_folder = f'/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2024Nov_output/SL_{method}/output_{percentile}/'\n",
    "        result_df = pd.DataFrame()\n",
    "\n",
    "        # Iterate over files in the folder\n",
    "        for folder_name in os.listdir(folder_path):\n",
    "            # Skip hidden and .csv files\n",
    "            if folder_name.endswith('.csv') or folder_name.startswith('.'):\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(folder_path, folder_name, 'Sediment.out')\n",
    "            if os.path.isfile(file_path):\n",
    "                # Read sediment data and calculate monthly sediment yield\n",
    "                sediments = pd.read_csv(file_path)\n",
    "                output_df = functions.calculate_monthly_sediment_yield_all(sediments, column)\n",
    "                \n",
    "                # Take the specified column and rename it\n",
    "                name_column = output_df[column]\n",
    "                column_name = f'{column}_{folder_name}'\n",
    "                result_df[column_name] = name_column\n",
    "                result_df.columns = [col[-3:] for col in result_df.columns]\n",
    "\n",
    "        # Filter and check columns with elevation list\n",
    "        result_df = result_df[elevation_list]\n",
    "        if elevation_list == result_df.columns.tolist():\n",
    "            print(\"default land cover. monthly data: same\")\n",
    "        else:\n",
    "            print(\"not the same\")\n",
    "\n",
    "        # Rename columns according to elevation, merge with timestep, and add land cover info\n",
    "        result_df.columns = elevation.loc['band_data']\n",
    "        result_df = pd.concat([df, result_df], axis=1)\n",
    "        result_df['land_cover'] = f'landcover{landcover_idx}'\n",
    "\n",
    "        # Save the DataFrame to a CSV file with both landcover and percentile in the filename\n",
    "        output_filename = f'{location}_monthly_sum_elevation_{column}_landcover{landcover_idx}_{percentile}.csv'\n",
    "        result_df.to_csv(os.path.join(output_folder, output_filename), index=False)\n",
    "\n",
    "        print(f\"Saved {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b3f0c0-a960-47d5-90db-644640c896f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8032369f-22b6-4074-8f01-b4dea993fc70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577f4efb-7ab3-41b9-b83b-12c439e56e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da1e468b-d85c-4f2d-b23e-69480e710b2d",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971391aa-982a-403e-b093-ec60d81936c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1 = pd.read_csv('/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_data_once/1landcover_50percent/langtang_climate_cut/14d/Sediment.out')\n",
    "# test2 = pd.read_csv('/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/SL_data_once/1landcover_60percent/langtang_climate_cut/14d/Sediment.out')\n",
    "\n",
    "test1 = pd.read_csv('/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_daily/1landcover_20percent/langtang_climate_cut/14d/Sediment.out')\n",
    "test2 = pd.read_csv('/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_daily/2landcover_40percent/langtang_climate_cut/14d/Sediment.out')\n",
    "test3 = pd.read_csv('/Volumes/Extreme SSD/202409_paper2_modelruns/30years/SL_daily/2landcover_50percent/langtang_climate_cut/14d/Sediment.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e801150e-016b-416e-9dbd-3cdb15153646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6931e0-a4a5-4ec5-be68-798246dc99ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec491e-db7d-428d-801f-81fb5bbcb5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef99c15-429d-476c-a8d9-b4ea9fee9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3.so.plot()\n",
    "test3.Q100.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b567538b-163f-436d-a30c-cc65c104e0dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sedcas] *",
   "language": "python",
   "name": "conda-env-sedcas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
