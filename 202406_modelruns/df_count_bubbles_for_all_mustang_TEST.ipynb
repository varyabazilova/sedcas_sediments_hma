{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec9691b1-6105-42a2-b000-b7d568ee4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import functions\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cf2905-b0c1-4b50-b86b-eb3b04ddc2da",
   "metadata": {},
   "source": [
    "### df vs ff, daily vs once, langtang vs mustang -> 4 rows total \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79ed15c2-dae5-4285-ac0c-682212e1ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions \n",
    "\n",
    "start_date = \"1990-07-31\"\n",
    "end_date = \"2021-06-30\"\n",
    "\n",
    "\n",
    "def filter_by_date(df, start_date = start_date, end_date = end_date, date_column='D'):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only rows where the date_column is within the given range.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        start_date (str or pd.Timestamp): The start date (inclusive).\n",
    "        end_date (str or pd.Timestamp): The end date (inclusive).\n",
    "        date_column (str): The column containing date values (default is 'D').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The filtered DataFrame.\n",
    "    \"\"\"\n",
    "    df[date_column] = pd.to_datetime(df[date_column])  # Convert to datetime\n",
    "    return df[(df[date_column] >= start_date) & (df[date_column] <= end_date)]\n",
    "\n",
    "\n",
    "# Define a function to categorize seasons\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'DJF'  # December, January, February (Winter)\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'MAM'  # March, April, May (Spring)\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'JJA'  # June, July, August (Summer)\n",
    "    else:\n",
    "        return 'SON'  # September, October, November (Autumn)\n",
    "\n",
    "# Define a function to categorize seasons\n",
    "def get_monsoon(month):\n",
    "    if month in [1, 2, 3, 4]:\n",
    "        return 'before monsoon'  \n",
    "    elif month in [5, 6, 7, 8, 9]:\n",
    "        return month  # should remain the same \n",
    "    elif month in [10, 11, 12]:\n",
    "        return 'after monsoon'  # June, July, August (Summer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prepare_dfcount_for_plot(dfcount):\n",
    "    \n",
    "    dfcount = dfcount.drop('folder', axis = 1)\n",
    "    \n",
    "    melted = pd.melt(dfcount, id_vars=['D', 'year', 'month'], var_name='elevation', value_name='dfs_count')\n",
    "    melted['elevation'] = melted['elevation'].str.split('.').str[0].astype(float)\n",
    "\n",
    "    melted['id'] = melted['D_year'].astype(str)+ \"_\" + melted['D_month'].astype(str) + \"_\" + melted['elevation'].astype(str)\n",
    "    \n",
    "    melted['elevation_bin'] = melted.apply(functions.bin_elevation500, axis=1)\n",
    "    melted = melted.sort_values('elevation_bin')\n",
    "    # melted = melted.dropna(subset=['dfs_count'])\n",
    "    return melted \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prepare_dfcount_for_barplot(dfcount, landcover_idx):\n",
    "    melted = pd.melt(dfcount, id_vars=['D', 'D_year', 'D_month'], var_name='elevation', value_name='dfs_count')\n",
    "    melted['elevation'] = melted['elevation'].str.split('.').str[0].astype(float)\n",
    "    melted['elevation_bin'] = melted.apply(functions.bin_elevation500, axis=1)\n",
    "   \n",
    "    # melted['id'] = melted['D_year'].astype(str)+ \"_\" + melted['D_month'].astype(str) + \"_\" + melted['elevation'].astype(str)\n",
    "\n",
    "    melted = melted.sort_values('elevation_bin')\n",
    "    melted['season'] = melted['D_month'].apply(get_season)\n",
    "    melted['monsoon'] = melted['D_month'].apply(get_monsoon)\n",
    "\n",
    "    melted['landcover'] = f'landcover {landcover_idx}'\n",
    "    return melted \n",
    "\n",
    "\n",
    "\n",
    "def merge_landcover_dfs(dfs, dfspot, merge_on, dfspot_column):\n",
    "    \"\"\"\n",
    "    Merges a list of dataframes on specified columns and adds a column from a 'dfspot' dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "        dfs (list of pd.DataFrame): List of dataframes to merge sequentially.\n",
    "        dfspot (pd.DataFrame): A dataframe containing a column to add after the merges.\n",
    "        merge_on (list of str): Columns to use as the merge keys.\n",
    "        dfspot_column (str): The name of the column in `dfspot` to add after merging.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The merged dataframe with the additional column from `dfspot`.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Start with the first dataframe in `dfs` and automatically get the count column\n",
    "    count_column = [col for col in dfs[0].columns if col.startswith('dfs_count')][0]\n",
    "    merged_df = dfs[0][merge_on + [count_column]]\n",
    "    \n",
    "    # Iterate over remaining dataframes and merge each sequentially\n",
    "    for df in dfs[1:]:\n",
    "        count_column = [col for col in df.columns if col.startswith('dfs_count')][0]\n",
    "        merged_df = pd.merge(merged_df, df[merge_on + [count_column]], on=merge_on)\n",
    "    \n",
    "    # Add the `dfspot_column` from `dfspot` dataframe to the merged dataframe\n",
    "    merged_df['dfspot_count'] = dfspot[dfspot_column]\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "\n",
    "def calculate_floods(df):\n",
    "    # df percent \n",
    "    df[f'dfs_count_60_percent'] = (df[f'dfs_count_60percent'] *100) / df.dfspot_count\n",
    "    df[f'dfs_count_50_percent'] = (df[f'dfs_count_50percent'] *100) / df.dfspot_count\n",
    "    df[f'dfs_count_40_percent'] = (df[f'dfs_count_40percent'] *100) / df.dfspot_count\n",
    "    df[f'dfs_count_30_percent'] = (df[f'dfs_count_30percent'] *100) / df.dfspot_count\n",
    "    df[f'dfs_count_20_percent'] = (df[f'dfs_count_20percent'] *100) / df.dfspot_count\n",
    "    # ff count \n",
    "    df[f'ffs_count_60'] = df.dfspot_count - df[f'dfs_count_60percent']\n",
    "    df[f'ffs_count_50'] = df.dfspot_count - df[f'dfs_count_50percent']\n",
    "    df[f'ffs_count_40'] = df.dfspot_count - df[f'dfs_count_40percent']\n",
    "    df[f'ffs_count_30'] = df.dfspot_count - df[f'dfs_count_30percent']\n",
    "    df[f'ffs_count_20'] = df.dfspot_count - df[f'dfs_count_20percent']\n",
    "    # ff percent\n",
    "    df[f'ffs_count_60_percent'] = (df[f'ffs_count_60'] *100) / df.dfspot_count\n",
    "    df[f'ffs_count_50_percent'] = (df[f'ffs_count_50'] *100) / df.dfspot_count\n",
    "    df[f'ffs_count_40_percent'] = (df[f'ffs_count_40'] *100) / df.dfspot_count\n",
    "    df[f'ffs_count_30_percent'] = (df[f'ffs_count_30'] *100) / df.dfspot_count\n",
    "    df[f'ffs_count_20_percent'] = (df[f'ffs_count_20'] *100) / df.dfspot_count\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f432e4-430d-477e-838c-26f09ee2f09f",
   "metadata": {},
   "source": [
    "# mustang - potential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "134f6048-f85d-42d9-98fa-d6143504a83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'mustang'\n",
    "\n",
    "# path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025Jan_output/TL/langtang/'\n",
    "path = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025Jan_output/TL/march2025mustang/'\n",
    "dfspot1_df = pd.read_csv(path + f'{location}_monthly_dfspot_count_landcover1.csv', index_col = 0).fillna(0)\n",
    "dfspot2_df = pd.read_csv(path + f'{location}_monthly_dfspot_count_landcover2.csv', index_col = 0).fillna(0)\n",
    "dfspot3_df = pd.read_csv(path + f'{location}_monthly_dfspot_count_landcover3.csv', index_col = 0).fillna(0)\n",
    "dfspot4_df = pd.read_csv(path + f'{location}_monthly_dfspot_count_landcover4.csv', index_col = 0).fillna(0)\n",
    "dfspot5_df = pd.read_csv(path + f'{location}_monthly_dfspot_count_landcover5.csv', index_col = 0).fillna(0)\n",
    "\n",
    "dfspot1_df = filter_by_date(dfspot1_df)\n",
    "dfspot2_df = filter_by_date(dfspot2_df)\n",
    "dfspot3_df = filter_by_date(dfspot3_df)\n",
    "dfspot4_df = filter_by_date(dfspot4_df)\n",
    "dfspot5_df = filter_by_date(dfspot5_df)\n",
    "\n",
    "dfspot1 = prepare_dfcount_for_barplot(dfspot1_df, 1).fillna(0)\n",
    "dfspot2 = prepare_dfcount_for_barplot(dfspot2_df, 2).fillna(0)\n",
    "dfspot3 = prepare_dfcount_for_barplot(dfspot3_df, 3).fillna(0)\n",
    "dfspot4 = prepare_dfcount_for_barplot(dfspot4_df, 4).fillna(0)\n",
    "dfspot5 = prepare_dfcount_for_barplot(dfspot5_df, 5).fillna(0)\n",
    "\n",
    "dfspot1 = dfspot1.rename(columns = {'D_year':'year', 'D_month':'month'})\n",
    "dfspot2 = dfspot2.rename(columns = {'D_year':'year', 'D_month':'month'})\n",
    "dfspot3 = dfspot3.rename(columns = {'D_year':'year', 'D_month':'month'})\n",
    "dfspot4 = dfspot4.rename(columns = {'D_year':'year', 'D_month':'month'})\n",
    "dfspot5 = dfspot5.rename(columns = {'D_year':'year', 'D_month':'month'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a9efefc-5dd4-42b0-b208-5b9005438292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>elevation</th>\n",
       "      <th>dfs_count</th>\n",
       "      <th>elevation_bin</th>\n",
       "      <th>season</th>\n",
       "      <th>monsoon</th>\n",
       "      <th>landcover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>2013-08-31</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>2886.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2500 - 3000</td>\n",
       "      <td>JJA</td>\n",
       "      <td>8</td>\n",
       "      <td>landcover 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>2886.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2500 - 3000</td>\n",
       "      <td>JJA</td>\n",
       "      <td>8</td>\n",
       "      <td>landcover 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>2010-09-30</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>2886.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2500 - 3000</td>\n",
       "      <td>SON</td>\n",
       "      <td>9</td>\n",
       "      <td>landcover 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>2010-10-31</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>2886.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2500 - 3000</td>\n",
       "      <td>SON</td>\n",
       "      <td>after monsoon</td>\n",
       "      <td>landcover 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>2010-11-30</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>2886.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2500 - 3000</td>\n",
       "      <td>SON</td>\n",
       "      <td>after monsoon</td>\n",
       "      <td>landcover 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31006</th>\n",
       "      <td>2001-05-31</td>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>6066.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>MAM</td>\n",
       "      <td>5</td>\n",
       "      <td>landcover 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31005</th>\n",
       "      <td>2001-04-30</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>6066.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>MAM</td>\n",
       "      <td>before monsoon</td>\n",
       "      <td>landcover 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31004</th>\n",
       "      <td>2001-03-31</td>\n",
       "      <td>2001</td>\n",
       "      <td>3</td>\n",
       "      <td>6066.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>MAM</td>\n",
       "      <td>before monsoon</td>\n",
       "      <td>landcover 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31014</th>\n",
       "      <td>2002-01-31</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>6066.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>DJF</td>\n",
       "      <td>before monsoon</td>\n",
       "      <td>landcover 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31095</th>\n",
       "      <td>2008-10-31</td>\n",
       "      <td>2008</td>\n",
       "      <td>10</td>\n",
       "      <td>6066.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>SON</td>\n",
       "      <td>after monsoon</td>\n",
       "      <td>landcover 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69936 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               D  year  month  elevation  dfs_count elevation_bin season  \\\n",
       "1765  2013-08-31  2013      8     2886.0        0.0   2500 - 3000    JJA   \n",
       "1729  2010-08-31  2010      8     2886.0        0.0   2500 - 3000    JJA   \n",
       "1730  2010-09-30  2010      9     2886.0        0.0   2500 - 3000    SON   \n",
       "1731  2010-10-31  2010     10     2886.0        0.0   2500 - 3000    SON   \n",
       "1732  2010-11-30  2010     11     2886.0        0.0   2500 - 3000    SON   \n",
       "...          ...   ...    ...        ...        ...           ...    ...   \n",
       "31006 2001-05-31  2001      5     6066.0        0.0          6000    MAM   \n",
       "31005 2001-04-30  2001      4     6066.0        0.0          6000    MAM   \n",
       "31004 2001-03-31  2001      3     6066.0        0.0          6000    MAM   \n",
       "31014 2002-01-31  2002      1     6066.0        0.0          6000    DJF   \n",
       "31095 2008-10-31  2008     10     6066.0        0.0          6000    SON   \n",
       "\n",
       "              monsoon    landcover  \n",
       "1765                8  landcover 3  \n",
       "1729                8  landcover 3  \n",
       "1730                9  landcover 3  \n",
       "1731    after monsoon  landcover 3  \n",
       "1732    after monsoon  landcover 3  \n",
       "...               ...          ...  \n",
       "31006               5  landcover 3  \n",
       "31005  before monsoon  landcover 3  \n",
       "31004  before monsoon  landcover 3  \n",
       "31014  before monsoon  landcover 3  \n",
       "31095   after monsoon  landcover 3  \n",
       "\n",
       "[69936 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfspot3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a70b46ac-3313-444a-abf3-d9db93af5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfspot3.date_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6442da69-8e38-4d0e-bf11-c8dd48846bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f910a5a-2038-48c9-919d-cf0220110f61",
   "metadata": {},
   "source": [
    "# once and daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8593fbdc-9bf1-43a6-800a-8f83674b6a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025Jan_output/SL_daily/output_30percent/langtang_monthly_dfs_count_30percent_landcover1.csv\n",
      "1\n",
      "/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025Jan_output/SL_daily/output_20percent/langtang_monthly_dfs_count_20percent_landcover1.csv\n",
      "1\n",
      "/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025Jan_output/SL_daily/output_60percent/langtang_monthly_dfs_count_60percent_landcover1.csv\n",
      "1\n",
      "/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025Jan_output/SL_daily/output_40percent/langtang_monthly_dfs_count_40percent_landcover1.csv\n",
      "1\n",
      "/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025Jan_output/SL_daily/output_50percent/langtang_monthly_dfs_count_50percent_landcover1.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['year', 'month', 'id'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/31/xdyntby945q7564txk4rqyh40000gp/T/ipykernel_78244/129496644.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mdfmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_landcover_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfspot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_on\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfspot_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mdffloods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_floods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfmerged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/31/xdyntby945q7564txk4rqyh40000gp/T/ipykernel_78244/1104079997.py\u001b[0m in \u001b[0;36mmerge_landcover_dfs\u001b[0;34m(dfs, dfspot, merge_on, dfspot_column)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# Start with the first dataframe in `dfs` and automatically get the count column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mcount_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs_count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmerge_on\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcount_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# Iterate over remaining dataframes and merge each sequentially\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sedcas/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sedcas/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sedcas/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['year', 'month', 'id'] not in index\""
     ]
    }
   ],
   "source": [
    "\n",
    "landcover_idx = 1\n",
    "method = 'daily'\n",
    "location = 'mustang'\n",
    "\n",
    "\n",
    "\n",
    "# Base directory where all output_Xpercent folders are located\n",
    "base_directory = f\"/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025Jan_output/SL_{method}/\"\n",
    "\n",
    "# Use glob to find all relevant files in output_XXpercent folders\n",
    "file_pattern = f\"{base_directory}/output_*/langtang_monthly_dfs_count_*_landcover{landcover_idx}.csv\"\n",
    "files = glob.glob(file_pattern)\n",
    "\n",
    "dfs = []\n",
    "\n",
    "# Loop through the files and process them\n",
    "for file in files:\n",
    "    # Extract the percentile from the folder name\n",
    "    percentile = re.search(r'output_(\\d+percent)', file).group(1)\n",
    "    \n",
    "    # Extract the landcover number from the file name\n",
    "    landcover_number = re.search(r'landcover(\\d+)', file).group(1)\n",
    "    print(landcover_number)\n",
    "    print(file)\n",
    "    # Read the file into a DataFrame\n",
    "    df = pd.read_csv(file, index_col=0).fillna(0)\n",
    "    df = filter_by_date(df)\n",
    "\n",
    "    # Apply your processing function\n",
    "    processed_df = prepare_dfcount_for_plot(df)\n",
    "    \n",
    "    # Rename the 'dfs_count' column to include percentile and landcover number\n",
    "    processed_df = processed_df.rename(columns={'dfs_count': f'dfs_count_{percentile}'})\n",
    "    # Append to the list\n",
    "    dfs.append(processed_df)\n",
    "\n",
    "merge_on = ['year', 'month', 'elevation', 'elevation_bin', 'id']\n",
    "dfspot_column = 'dfs_count'\n",
    "\n",
    "if landcover_idx == 1:\n",
    "    dfspot = dfspot1\n",
    "if landcover_idx == 2:\n",
    "    dfspot = dfspot2\n",
    "if landcover_idx == 3:\n",
    "    dfspot = dfspot3\n",
    "if landcover_idx == 4:\n",
    "    dfspot = dfspot4\n",
    "if landcover_idx == 5:\n",
    "    dfspot = dfspot5\n",
    "\n",
    "\n",
    "dfmerged = merge_landcover_dfs(dfs, dfspot, merge_on, dfspot_column)\n",
    "dffloods = calculate_floods(dfmerged)\n",
    "\n",
    "\n",
    "outpath = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025Jan_output/df_vs_floods/mustang_test/'\n",
    "# dffloods.to_csv(outpath + f'{location}_df_vs_floods_{method}_landcover{landcover_idx}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca30e758-1b64-43fb-bf2b-54a0b22b16b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>3689.0</th>\n",
       "      <th>2546.0</th>\n",
       "      <th>3964.0</th>\n",
       "      <th>2571.0</th>\n",
       "      <th>2886.0</th>\n",
       "      <th>3795.0</th>\n",
       "      <th>3540.0</th>\n",
       "      <th>4420.0</th>\n",
       "      <th>...</th>\n",
       "      <th>4785.0</th>\n",
       "      <th>4439.0</th>\n",
       "      <th>4593.0</th>\n",
       "      <th>4603.0</th>\n",
       "      <th>4733.0</th>\n",
       "      <th>4905.0</th>\n",
       "      <th>4952.0</th>\n",
       "      <th>4812.0</th>\n",
       "      <th>4889.0</th>\n",
       "      <th>folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mustang_climate_cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mustang_climate_cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mustang_climate_cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>1989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mustang_climate_cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mustang_climate_cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.726750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.708209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mustang_climate_cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>6</td>\n",
       "      <td>2022</td>\n",
       "      <td>58.594102</td>\n",
       "      <td>132.535223</td>\n",
       "      <td>54.037074</td>\n",
       "      <td>132.259252</td>\n",
       "      <td>61.169990</td>\n",
       "      <td>37.680373</td>\n",
       "      <td>46.224046</td>\n",
       "      <td>37.695656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mustang_climate_cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>7</td>\n",
       "      <td>2022</td>\n",
       "      <td>193.335784</td>\n",
       "      <td>353.241563</td>\n",
       "      <td>175.066199</td>\n",
       "      <td>345.650127</td>\n",
       "      <td>345.187199</td>\n",
       "      <td>201.240182</td>\n",
       "      <td>227.389835</td>\n",
       "      <td>155.959179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mustang_climate_cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>17.996708</td>\n",
       "      <td>69.527600</td>\n",
       "      <td>14.075152</td>\n",
       "      <td>73.409143</td>\n",
       "      <td>142.442272</td>\n",
       "      <td>67.632671</td>\n",
       "      <td>107.280142</td>\n",
       "      <td>40.589535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mustang_climate_cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mustang_climate_cut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  year      3689.0      2546.0      3964.0      2571.0      2886.0  \\\n",
       "0        9  1989    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1       10  1989    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2       11  1989    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "3       12  1989    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "4        1  1990    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "..     ...   ...         ...         ...         ...         ...         ...   \n",
       "392      5  2022    0.000000    3.726750    0.000000    3.708209    0.000000   \n",
       "393      6  2022   58.594102  132.535223   54.037074  132.259252   61.169990   \n",
       "394      7  2022  193.335784  353.241563  175.066199  345.650127  345.187199   \n",
       "395      8  2022   17.996708   69.527600   14.075152   73.409143  142.442272   \n",
       "396      9  2022    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "         3795.0      3540.0      4420.0  ...  4785.0  4439.0  4593.0  4603.0  \\\n",
       "0      0.000000    0.000000    0.000000  ...     0.0     0.0     0.0     0.0   \n",
       "1      0.000000    0.000000    0.000000  ...     0.0     0.0     0.0     0.0   \n",
       "2      0.000000    0.000000    0.000000  ...     0.0     0.0     0.0     0.0   \n",
       "3      0.000000    0.000000    0.000000  ...     0.0     0.0     0.0     0.0   \n",
       "4      0.000000    0.000000    0.000000  ...     0.0     0.0     0.0     0.0   \n",
       "..          ...         ...         ...  ...     ...     ...     ...     ...   \n",
       "392    0.000000    0.000000    0.000000  ...     0.0     0.0     0.0     0.0   \n",
       "393   37.680373   46.224046   37.695656  ...     0.0     0.0     0.0     0.0   \n",
       "394  201.240182  227.389835  155.959179  ...     0.0     0.0     0.0     0.0   \n",
       "395   67.632671  107.280142   40.589535  ...     0.0     0.0     0.0     0.0   \n",
       "396    0.000000    0.000000    0.000000  ...     0.0     0.0     0.0     0.0   \n",
       "\n",
       "     4733.0  4905.0  4952.0  4812.0  4889.0               folder  \n",
       "0       0.0     0.0     0.0     0.0     0.0  mustang_climate_cut  \n",
       "1       0.0     0.0     0.0     0.0     0.0  mustang_climate_cut  \n",
       "2       0.0     0.0     0.0     0.0     0.0  mustang_climate_cut  \n",
       "3       0.0     0.0     0.0     0.0     0.0  mustang_climate_cut  \n",
       "4       0.0     0.0     0.0     0.0     0.0  mustang_climate_cut  \n",
       "..      ...     ...     ...     ...     ...                  ...  \n",
       "392     0.0     0.0     0.0     0.0     0.0  mustang_climate_cut  \n",
       "393     0.0     0.0     0.0     0.0     0.0  mustang_climate_cut  \n",
       "394     0.0     0.0     0.0     0.0     0.0  mustang_climate_cut  \n",
       "395     0.0     0.0     0.0     0.0     0.0  mustang_climate_cut  \n",
       "396     0.0     0.0     0.0     0.0     0.0  mustang_climate_cut  \n",
       "\n",
       "[397 rows x 191 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025Jan_output/SL_once/output_20percent/mustang_monthly_sum_elevation_dfs_20percent_1landcover_mm.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cb99096-0dad-45eb-ad42-6a047b02cc60",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The following 'id_vars' are not present in the DataFrame: ['D']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/31/xdyntby945q7564txk4rqyh40000gp/T/ipykernel_78244/4129220747.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_dfcount_for_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/31/xdyntby945q7564txk4rqyh40000gp/T/ipykernel_78244/4030709493.py\u001b[0m in \u001b[0;36mprepare_dfcount_for_plot\u001b[0;34m(dfcount)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mdfcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'folder'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmelted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'D'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'month'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'elevation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dfs_count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mmelted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'elevation'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmelted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'elevation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sedcas/lib/python3.9/site-packages/pandas/core/reshape/melt.py\u001b[0m in \u001b[0;36mmelt\u001b[0;34m(frame, id_vars, value_vars, var_name, value_name, col_level, ignore_index)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m     83\u001b[0m                     \u001b[0;34m\"The following 'id_vars' are not present \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0;34mf\"in the DataFrame: {list(missing)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The following 'id_vars' are not present in the DataFrame: ['D']\""
     ]
    }
   ],
   "source": [
    "test = prepare_dfcount_for_plot(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babdf80d-c989-4d82-88fe-3f39f34689a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b8ae3-91a1-4933-93a4-0f74c0deafb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9766a0-4bfb-433f-8c2f-f0dcf300cbab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3679ee-e5ad-45d5-bb98-536a23450a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb47e88-56fc-412e-91a3-5f227982e44b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a44587-e91f-4db1-aebb-d067dcdd27c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b6202d-2c57-4395-8552-bc848ca25bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b550c6-323e-4323-804a-be39f3f8b0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22869df5-cbec-4b3d-b13e-1ecafbf8dfad",
   "metadata": {},
   "source": [
    "# plots with bubbles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc4813-f653-4387-a99d-ba6fccc5511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read those files \n",
    "outpath = '/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/2025Jan_output/df_vs_floods/'\n",
    "\n",
    "landcover1O = pd.read_csv(outpath + 'langtang_df_vs_floods_once_landcover1.csv', index_col=0)\n",
    "landcover2O = pd.read_csv(outpath + 'langtang_df_vs_floods_once_landcover2.csv', index_col=0)\n",
    "landcover3O = pd.read_csv(outpath + 'langtang_df_vs_floods_once_landcover3.csv', index_col=0)\n",
    "landcover4O = pd.read_csv(outpath + 'langtang_df_vs_floods_once_landcover4.csv', index_col=0)\n",
    "landcover5O = pd.read_csv(outpath + 'langtang_df_vs_floods_once_landcover5.csv', index_col=0)\n",
    "\n",
    "\n",
    "landcover1D = pd.read_csv(outpath + 'langtang_df_vs_floods_daily_landcover1.csv', index_col=0)\n",
    "landcover2D = pd.read_csv(outpath + 'langtang_df_vs_floods_daily_landcover2.csv', index_col=0)\n",
    "landcover3D = pd.read_csv(outpath + 'langtang_df_vs_floods_daily_landcover3.csv', index_col=0)\n",
    "landcover4D = pd.read_csv(outpath + 'langtang_df_vs_floods_daily_landcover4.csv', index_col=0)\n",
    "landcover5D = pd.read_csv(outpath + 'langtang_df_vs_floods_daily_landcover5.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959d634a-5311-474a-98ab-df282eb17109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check the \"empty\" elevation bins without any DFs potentially \n",
    "\n",
    "# dfs = {\"df1\": landcover1, \"df2\": landcover2, \"df3\": landcover3, \"df4\": landcover4, \"df5\": landcover5}  # Example dictionary of dataframes\n",
    "\n",
    "# empty_bins_per_df = {}\n",
    "\n",
    "# for name, df in dfs.items():\n",
    "#     # empty_bins = df.groupby(\"elevation_bin\")[\"dfspot_count\"].apply(lambda x: (x.isna() | (x == 0)).all())\n",
    "#     empty_bins = df.groupby(\"elevation_bin\")[\"dfspot_count\"].apply(lambda x: (x.isna()).all())\n",
    "#     empty_bins_per_df[name] = empty_bins[empty_bins].index.tolist()\n",
    "\n",
    "# # Print results\n",
    "# for name, empty_bins in empty_bins_per_df.items():\n",
    "#     print(f\"Elevation bins with only 0/NaN dfspot in {name}: {empty_bins}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5102f4e0-3db6-4c5c-a3a3-5c36d6f188d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def monthly_mean_per_elevation(df):\n",
    "#     mean = df.groupby(['elevation_bin', 'month']).mean().reset_index() \n",
    "#     return mean\n",
    "    \n",
    "def monthly_mean(df):\n",
    "    mean = df.groupby(['month']).mean().reset_index() \n",
    "    return mean\n",
    "\n",
    "\n",
    "# landcover1monthly_comb = monthly_mean(landcover1)\n",
    "# landcover2monthly_comb = monthly_mean(landcover2)\n",
    "# landcover3monthly_comb = monthly_mean(landcover3)\n",
    "# landcover4monthly_comb = monthly_mean(landcover4)\n",
    "# landcover5monthly_comb = monthly_mean(landcover5)\n",
    "\n",
    "\n",
    "landcover1monthlyO = monthly_mean(landcover1O)\n",
    "landcover2monthlyO = monthly_mean(landcover2O)\n",
    "landcover3monthlyO = monthly_mean(landcover3O)\n",
    "landcover4monthlyO = monthly_mean(landcover4O)\n",
    "landcover5monthlyO = monthly_mean(landcover5O)\n",
    "\n",
    "landcover1monthlyO['landcover']='landcover 1'\n",
    "landcover2monthlyO['landcover']='landcover 2'\n",
    "landcover3monthlyO['landcover']='landcover 3'\n",
    "landcover4monthlyO['landcover']='landcover 4'\n",
    "landcover5monthlyO['landcover']='landcover 5'\n",
    "\n",
    "landcover1monthlyD = monthly_mean(landcover1D)\n",
    "landcover2monthlyD = monthly_mean(landcover2D)\n",
    "landcover3monthlyD = monthly_mean(landcover3D)\n",
    "landcover4monthlyD = monthly_mean(landcover4D)\n",
    "landcover5monthlyD = monthly_mean(landcover5D)\n",
    "\n",
    "\n",
    "landcover1monthlyD['landcover']='landcover 1'\n",
    "landcover2monthlyD['landcover']='landcover 2'\n",
    "landcover3monthlyD['landcover']='landcover 3'\n",
    "landcover4monthlyD['landcover']='landcover 4'\n",
    "landcover5monthlyD['landcover']='landcover 5'\n",
    "\n",
    "landcover_all_month_daily = pd.concat([landcover1monthlyD, landcover2monthlyD, landcover3monthlyD, \n",
    "                                       landcover4monthlyD, landcover5monthlyD])\n",
    "\n",
    "landcover_all_month_once = pd.concat([landcover1monthlyO, landcover2monthlyO, landcover3monthlyO, \n",
    "                                      landcover4monthlyO, landcover5monthlyO])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ff5cd-d01c-4d8b-a2bd-82ce042be3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ddcea2-434b-4237-acbf-c9cd4a445292",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdaily1= landcover_all_month_daily[landcover_all_month_daily['landcover'].str.strip() == 'landcover 5']\n",
    "testonce1= landcover_all_month_once[landcover_all_month_once['landcover'].str.strip() ==    'landcover 5']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af0f757-2f63-489a-88af-0ed0f71ea6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5), layout='tight')\n",
    "mosaic = fig.subplot_mosaic('''\n",
    "                            abcde\n",
    "                            ABCDE\n",
    "                            ''')\n",
    "\n",
    "\n",
    "sns.barplot(data = testdaily1, y = 'dfs_count_20_percent', x='month', ax = mosaic['a'], hue = 'dfspot_count')\n",
    "sns.barplot(data = testdaily1, y = 'dfs_count_30_percent', x='month', ax = mosaic['b'], hue = 'dfspot_count')#, hue = 'elevation_bin',, legend = False)\n",
    "sns.barplot(data = testdaily1, y = 'dfs_count_40_percent', x='month', ax = mosaic['c'], hue = 'dfspot_count')#, hue = 'elevation_bin',, legend = False)\n",
    "sns.barplot(data = testdaily1, y = 'dfs_count_50_percent', x='month', ax = mosaic['d'], hue = 'dfspot_count')\n",
    "sns.barplot(data = testdaily1, y = 'dfs_count_60_percent', x='month', ax = mosaic['e'], hue = 'dfspot_count')\n",
    "\n",
    "sns.barplot(data = testonce1, y = 'dfs_count_20_percent', x='month', ax = mosaic['A'], hue = 'dfspot_count')\n",
    "sns.barplot(data = testonce1, y = 'dfs_count_30_percent', x='month', ax = mosaic['B'], hue = 'dfspot_count')#, hue = 'elevation_bin',, legend = False)\n",
    "sns.barplot(data = testonce1, y = 'dfs_count_40_percent', x='month', ax = mosaic['C'], hue = 'dfspot_count')#, hue = 'elevation_bin',, legend = False)\n",
    "sns.barplot(data = testonce1, y = 'dfs_count_50_percent', x='month', ax = mosaic['D'], hue = 'dfspot_count')\n",
    "sns.barplot(data = testonce1, y = 'dfs_count_60_percent', x='month', ax = mosaic['E'], hue = 'dfspot_count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba7bbaa-de8e-4c60-b57b-a5a057111b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb81ab-bbe6-455f-8e48-c6b9557105b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# landcover_all_month_daily.columns\n",
    "# which columns do i care about?\n",
    "\n",
    "# ffs_count_60_percent\n",
    "# dfs_count_60_percent\n",
    "# dfspot_count\n",
    "\n",
    "'''\n",
    "'dfspot_count', \n",
    "'dfs_count_60_percent',\n",
    "'dfs_count_50_percent', \n",
    "'dfs_count_40_percent', \n",
    "'dfs_count_30_percent',\n",
    "'dfs_count_20_percent', \n",
    "'ffs_count_60_percent',\n",
    "'ffs_count_50_percent', \n",
    "'ffs_count_40_percent', \n",
    "'ffs_count_30_percent',\n",
    "'ffs_count_20_percent', \n",
    "'landcover'\n",
    "'''\n",
    "# landcover_all_month_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeee5c8-ab6c-4f97-a85f-8c3a929cb924",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily20 = landcover_all_month_daily[['dfs_count_20_percent','ffs_count_20_percent', 'dfspot_count', 'landcover', 'month','year',\t'elevation']]\n",
    "daily30 = landcover_all_month_daily[['dfs_count_30_percent','ffs_count_30_percent', 'dfspot_count', 'landcover', 'month','year',\t'elevation']]\n",
    "daily40 = landcover_all_month_daily[['dfs_count_40_percent','ffs_count_40_percent', 'dfspot_count', 'landcover', 'month','year',\t'elevation']]\n",
    "daily50 = landcover_all_month_daily[['dfs_count_50_percent','ffs_count_50_percent', 'dfspot_count', 'landcover', 'month','year',\t'elevation']]\n",
    "daily60 = landcover_all_month_daily[['dfs_count_60_percent','ffs_count_60_percent', 'dfspot_count', 'landcover', 'month','year',\t'elevation']]\n",
    "\n",
    "once20 = landcover_all_month_once[['dfs_count_20_percent','ffs_count_20_percent', 'dfspot_count', 'landcover', 'month','year',\t'elevation']]\n",
    "once30 = landcover_all_month_once[['dfs_count_30_percent','ffs_count_30_percent', 'dfspot_count', 'landcover', 'month','year',\t'elevation']]\n",
    "once40 = landcover_all_month_once[['dfs_count_40_percent','ffs_count_40_percent', 'dfspot_count', 'landcover', 'month','year',\t'elevation']]\n",
    "once50 = landcover_all_month_once[['dfs_count_50_percent','ffs_count_50_percent', 'dfspot_count', 'landcover', 'month','year',\t'elevation']]\n",
    "once60 = landcover_all_month_once[['dfs_count_60_percent','ffs_count_60_percent', 'dfspot_count', 'landcover', 'month','year',\t'elevation']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dbbaba-651b-4636-9224-9da5b75a6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a function to rename columns\n",
    "def rename_and_add_column(df, percentile):\n",
    "    df = df.rename(columns={\n",
    "        df.columns[0]: 'dfs_count_percent',  # Renaming first column\n",
    "        df.columns[1]: 'ffs_count_percent'   # Renaming second column\n",
    "    })\n",
    "    df['percentile_input'] = f'{percentile} percent'\n",
    "    return df\n",
    "\n",
    "# Rename and add column for each dataframe\n",
    "daily20 = rename_and_add_column(daily20, 20)\n",
    "daily30 = rename_and_add_column(daily30, 30)\n",
    "daily40 = rename_and_add_column(daily40, 40)\n",
    "daily50 = rename_and_add_column(daily50, 50)\n",
    "daily60 = rename_and_add_column(daily60, 60)\n",
    "\n",
    "# Concatenate all dataframes\n",
    "df_daily = pd.concat([daily20, daily30, daily40, daily50, daily60], ignore_index=True)\n",
    "\n",
    "df_daily1= df_daily[df_daily.landcover =='landcover 1']\n",
    "df_daily2= df_daily[df_daily.landcover =='landcover 2']\n",
    "df_daily3= df_daily[df_daily.landcover =='landcover 3']\n",
    "df_daily4= df_daily[df_daily.landcover =='landcover 4']\n",
    "df_daily5= df_daily[df_daily.landcover =='landcover 5']\n",
    "\n",
    "\n",
    "# Rename and add column for each dataframe\n",
    "once20 = rename_and_add_column(once20, 20)\n",
    "once30 = rename_and_add_column(once30, 30)\n",
    "once40 = rename_and_add_column(once40, 40)\n",
    "once50 = rename_and_add_column(once50, 50)\n",
    "once60 = rename_and_add_column(once60, 60)\n",
    "\n",
    "# Concatenate all dataframes\n",
    "df_once = pd.concat([once20, once30, once40, once50, once60], ignore_index=True)\n",
    "\n",
    "df_once1= df_once[df_once.landcover =='landcover 1']\n",
    "df_once2= df_once[df_once.landcover =='landcover 2']\n",
    "df_once3= df_once[df_once.landcover =='landcover 3']\n",
    "df_once4= df_once[df_once.landcover =='landcover 4']\n",
    "df_once5= df_once[df_once.landcover =='landcover 5']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50189b21-9e53-4526-8813-fdf0b6a57824",
   "metadata": {},
   "source": [
    "# final plot for langtang! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e677c4-d6c1-4809-be5d-0f1f955e4b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = 0\n",
    "vmax = 100\n",
    "center = vmax/2\n",
    "# Convert categorical landcover to numeric for plotting\n",
    "percentile_numeric, percentile_labels = pd.factorize(df_once1.percentile_input)\n",
    "\n",
    "# # Define normalization with midpoint at 50%\n",
    "norm = mcolors.TwoSlopeNorm(vmin=vmin, vcenter=center, vmax=vmax)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5.8), layout='tight')\n",
    "mosaic = fig.subplot_mosaic('''\n",
    "                            ABCDE\n",
    "                            abcde\n",
    "                            abcde\n",
    "                            abcde\n",
    "                            abcde\n",
    "                            abcde\n",
    "                            abcde\n",
    "                            ''')\n",
    "\n",
    "# List of subplot keys where the grey background should be applied\n",
    "target_axes = ['a', 'b', 'c', 'd', 'e']\n",
    "\n",
    "# Apply axvspan **only to the target axes**\n",
    "for key in target_axes:\n",
    "    mosaic[key].axvspan(5 - 0.5, 9 + 0.5, color='grey', alpha=0.15)\n",
    "\n",
    "s1 = mosaic['a'].scatter(x = df_daily1.month, y = percentile_numeric-0.20, c = df_daily1.dfs_count_percent, s = df_daily1.dfspot_count*100, cmap = 'coolwarm', norm=norm, edgecolor = 'none')\n",
    "mosaic['a'].scatter(x = df_once1.month, y = percentile_numeric+0.20, c = df_once1.dfs_count_percent, s = df_once1.dfspot_count*100, cmap = 'coolwarm', norm=norm, edgecolor = 'none')\n",
    "\n",
    "mosaic['b'].scatter(x = df_daily2.month, y = percentile_numeric-0.20, c = df_daily2.dfs_count_percent, s = df_daily2.dfspot_count*100, cmap = 'coolwarm', norm=norm,  edgecolor = 'none')\n",
    "mosaic['b'].scatter(x = df_once2.month,  y = percentile_numeric+0.20,  c = df_once2.dfs_count_percent,  s = df_once2.dfspot_count*100, cmap = 'coolwarm', norm=norm)\n",
    "\n",
    "mosaic['c'].scatter(x = df_daily3.month, y = percentile_numeric-0.20, c = df_daily3.dfs_count_percent, s = df_daily3.dfspot_count*100, cmap = 'coolwarm', norm=norm,  edgecolor = 'none')\n",
    "mosaic['c'].scatter(x = df_once3.month,  y = percentile_numeric+0.20,  c = df_once3.dfs_count_percent,  s = df_once3.dfspot_count*100, cmap = 'coolwarm', norm=norm)\n",
    "\n",
    "mosaic['d'].scatter(x = df_daily4.month, y = percentile_numeric-0.20, c = df_daily4.dfs_count_percent, s = df_daily4.dfspot_count*100, cmap = 'coolwarm', norm=norm,  edgecolor = 'none')\n",
    "mosaic['d'].scatter(x = df_once4.month,  y = percentile_numeric+0.20,  c = df_once4.dfs_count_percent,  s = df_once4.dfspot_count*100, cmap = 'coolwarm', norm=norm)\n",
    "\n",
    "\n",
    "mosaic['e'].scatter(x = df_daily5.month, y = percentile_numeric-0.20, c = df_daily5.dfs_count_percent, s = df_daily5.dfspot_count*100, cmap = 'coolwarm', norm=norm,  edgecolor = 'none')\n",
    "mosaic['e'].scatter(x = df_once5.month,  y = percentile_numeric+0.20,  c = df_once5.dfs_count_percent,  s = df_once5.dfspot_count*100, cmap = 'coolwarm', norm=norm)\n",
    "\n",
    "\n",
    "mosaic['a'].set_yticks(range(len(percentile_labels)))\n",
    "mosaic['a'].set_yticklabels(percentile_labels)\n",
    "\n",
    "\n",
    "\n",
    "# cbar1 = fig.colorbar(s1, ax=mosaic['e'], orientation='vertical', fraction=0.1, pad=0.1)\n",
    "\n",
    "\n",
    "# -------------------\n",
    "\n",
    "for key in ['a', 'b', 'c', 'd', 'e']:\n",
    "    mosaic[key].set_xticks(df_once1.month.unique())  # Set tick positions\n",
    "    mosaic[key].set_xticklabels(df_once1.month.unique(), rotation=45)  # Set tick labels, rotate\n",
    "\n",
    "for key in ['a']:\n",
    "    mosaic[key].set_yticks(range(len(percentile_labels)))\n",
    "    mosaic[key].set_yticklabels(percentile_labels)\n",
    "\n",
    "for key in ['b', 'c', 'd', 'e']:\n",
    "    mosaic[key].set_yticklabels([])\n",
    "\n",
    "\n",
    "mosaic['A'].set_title('landcover 1')\n",
    "mosaic['B'].set_title('landcover 2')\n",
    "mosaic['C'].set_title('landcover 3')\n",
    "mosaic['D'].set_title('landcover 4')\n",
    "mosaic['E'].set_title('landcover 5')\n",
    "\n",
    "\n",
    "# plt.savefig(outpath + 'bubble_plot_landcover_panels_new_legend.png', dpi = 300, bbox_inches = 'tight')\n",
    "plt.suptitle('langtang, df count across all elevations', fontsize = 20)\n",
    "\n",
    "\n",
    "# color bar for land cover shares \n",
    "\n",
    "# Define color proportions for each panel (Green, Yellow, Gray)\n",
    "shares = [\n",
    "    (40, 40, 20),  # First bar: 40% green (veg) , 30% grey (bedrock), 30% blue (glacier)\n",
    "    (40, 50, 10),\n",
    "    (50, 40, 10),\n",
    "    (40, 60, 00),\n",
    "    (60, 40, 00),\n",
    "]\n",
    "\n",
    "# Iterate over the bar row and create the proportional bars\n",
    "for i, key in enumerate(\"ABCDE\"):\n",
    "    bar_ax = mosaic[key]  # Select the correct subplot for the bar\n",
    "\n",
    "    # Remove ticks, labels, and spines\n",
    "    bar_ax.set_xticks([])\n",
    "    bar_ax.set_yticks([])\n",
    "    bar_ax.set_frame_on(False)\n",
    "\n",
    "    # Extract proportions (must sum to 100%)\n",
    "    p1, p2, p3 = shares[i]  # Green, Yellow, Gray\n",
    "\n",
    "    # Convert percentages to width (normalized to 1)\n",
    "    p1 /= 100\n",
    "    p2 /= 100\n",
    "    p3 /= 100\n",
    "\n",
    "    # Plot the three segments\n",
    "    bar_ax.barh(0, p1, height=1, color='green', align='center', alpha = 0.8)\n",
    "    bar_ax.barh(0, p2, height=1, color='lightgray', left=p1, align='center')\n",
    "    bar_ax.barh(0, p3, height=1, color='lightblue', left=p1 + p2, align='center')\n",
    "\n",
    "    # # Add percentage label (can be adjusted)\n",
    "    # bar_ax.text(0.5, 0, f\"{shares[i][0]}% / {shares[i][1]}% / {shares[i][2]}%\", \n",
    "    #             ha='center', va='center', fontsize=12, color='black', weight='bold')\n",
    "\n",
    "\n",
    "# plt.savefig('/Users/varyabazilova/Desktop/paper2/202406_modelruns/30years/output/testplots/bubble_plot_landcover_panels_new_legend.png', bbox_inches = 'tight', dpi = 300)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f66a32c-ff18-4769-9c93-3d7bf774c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd060ae-990c-4b8f-8222-3d3138abe665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_daily1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcc7933-04b3-4bab-9470-0d249225f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_once1[df_once1['percentile_input'] =='20 percent'].dfs_count_percent.plot(label = 'once')\n",
    "df_daily1[df_daily1['percentile_input'] =='20 percent'].dfs_count_percent.plot(label = 'daily')\n",
    "plt.hline(\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4853f15e-5f23-40f5-9844-767d93a6b90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_once1.dfs_count_percent.plot()\n",
    "df_daily1.dfs_count_percent.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15addd78-6869-4619-bd64-e7faea234ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_once2.dfs_count_percent.plot()\n",
    "df_daily2.dfs_count_percent.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef034598-0c9e-46ff-b4fb-f2192dabffda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909ac78-2368-4767-90ae-9a42a468e2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sedcas] *",
   "language": "python",
   "name": "conda-env-sedcas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
